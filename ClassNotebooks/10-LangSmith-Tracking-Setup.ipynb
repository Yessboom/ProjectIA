{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangSmith Tracking Setup\n",
    "\n",
    "This Tutorial comes [LangChain Open Tutorial](https://github.com/LangChain-OpenTutorial/LangChain-OpenTutorial) with minor Changes by Martin Fockedey\n",
    "\n",
    "- Author: [JeongGi Park](https://github.com/jeongkpa)\n",
    "- Peer Review: [MinJi Kang](https://www.linkedin.com/in/minji-kang-995b32230/), [Wooseok Jeong](https://github.com/jeong-wooseok)\n",
    "- Proofread : [Q0211](https://github.com/Q0211)\n",
    "- This is a part of [LangChain Open Tutorial](https://github.com/LangChain-OpenTutorial/LangChain-OpenTutorial)\n",
    "\n",
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/LangChain-OpenTutorial/LangChain-OpenTutorial/blob/main/01-Basic/04-LangSmith-Tracking-Setup.ipynb)[![Open in GitHub](https://img.shields.io/badge/Open%20in%20GitHub-181717?style=flat-square&logo=github&logoColor=white)](https://github.com/LangChain-OpenTutorial/LangChain-OpenTutorial/blob/main/01-Basic/04-LangSmith-Tracking-Setup.ipynb)\n",
    "## Overview\n",
    "\n",
    "This tutorial covers how to set up and use ```LangSmith```, a powerful platform for developing, monitoring, and testing LLM applications. \n",
    "```LangSmith``` provides comprehensive tracking capabilities that are essential for understanding and optimizing your LLM applications.\n",
    "\n",
    "```LangSmith``` tracking helps you monitor:\n",
    "\n",
    "- Token usage and associated costs\n",
    "- Execution time and performance metrics\n",
    "- Error rates and unexpected behaviors\n",
    "- Agent interactions and chain operations\n",
    "\n",
    "In this tutorial, we'll walk through the process of setting up ```LangSmith``` tracking and integrating it with your ```LangChain``` applications.\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "- [Overview](#overview)\n",
    "- [Setting up a LangSmith trace](#setting-up-a-langsmith-trace)\n",
    "- [Using LangSmith tracking](#using-langsmith-tracking)\n",
    "- [Enable tracking in your Jupyter notebook or code](#enable-tracking-in-your-jupyter-notebook-or-code)\n",
    "\n",
    "### References\n",
    "\n",
    "- [OpenAI API Pricing](https://openai.com/api/pricing/)\n",
    "- [Token Usage Guide](https://help.openai.com/en/articles/4936856-what-are-tokens-and-how-to-count-them)\n",
    "- [LangChain Python API Reference](https://python.langchain.com/api_reference/community/callbacks/langchain_community.callbacks.manager.get_openai_callback.html)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up a LangSmith trace\n",
    "\n",
    "```LangSmith``` is a platform for developing, monitoring, and testing LLM applications. \n",
    "If you're starting a project or learning ```LangChain```, ```LangSmith``` is a must-have to get set up and running."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project-Level Tracking\n",
    "At the project level, you can check execution counts, error rates, token usage, and billing information.\n",
    "\n",
    "![project-level-tracking](./assets/03-langsmith-tracking-setup-01.png)\n",
    "\n",
    "When you click on a project, all executed Runs appear.\n",
    "\n",
    "![project-level-tracking-detail](./assets/03-langsmith-tracking-setup-02.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detailed Step-by-Step Tracking for a Single Execution\n",
    "\n",
    "![detailed-step-by-step-tracking](./assets/03-langsmith-tracking-setup-03.png)\n",
    "\n",
    "\n",
    "After a single execution, it records not only the search results of retrieved documents but also detailed logs of GPT's input and output content. \n",
    "Therefore, it helps you determine whether to change the search algorithm or modify prompts after reviewing the searched content.\n",
    "\n",
    "\n",
    "Moreover, at the top, it shows the time taken for a single Run (about 30 seconds) and tokens used (5,104), and when you hover over the tokens, it displays the billing amount."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using LangSmith tracking\n",
    "\n",
    "Using traces is very simple."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get a LangSmith API Key\n",
    "\n",
    "\n",
    "1. Go to https://smith.langchain.com/ and sign up.\n",
    "2. After signing up, you will need to verify your email.\n",
    "3. Click the left cog (Setting) - center \"Personal\" - \"Create API Key\" to get an API key.\n",
    "\n",
    "![get-api-key](./assets/03-langsmith-tracking-setup-04.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Description, enter a description that makes sense to you and click the Create API Key button.\n",
    "\n",
    "![create-api-key](./assets/03-langsmith-tracking-setup-05.png\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy the generated key and proceed to the next step.\n",
    "\n",
    "(Caution!) Copy the generated key somewhere safe so that it doesn't leak.\n",
    "\n",
    "![copy-api-key](./assets/03-langsmith-tracking-setup-06.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting the LangSmith key in ```.env```\n",
    "\n",
    "\n",
    "First, enter the key you received from LangSmith and your project information in the .env file.\n",
    "\n",
    "- ```LANGCHAIN_TRACING_V2```: Set to \"true\" to start tracking.\n",
    "- ```LANGCHAIN_ENDPOINT```: https://api.smith.langchain.com (Do not modify this value).\n",
    "- ```LANGCHAIN_API_KEY```: Enter the key you received in the previous step.\n",
    "- ```LANGCHAIN_PROJECT```: Specify a project name to group and trace all runs under that project group.\n",
    "\n",
    "![setting-api-key](./assets/03-langsmith-tracking-setup-07.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enable tracking in your Jupyter notebook or code\n",
    "\n",
    "Enabling tracking is very simple. All you need to do is set an environment variable.\n",
    "\n",
    "Copy the contents of ```.env_sample``` and load it into your ```.env``` with the key you set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.3\n",
      "[notice] To update, run: C:\\Users\\FKY\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As long as your traces are enabled and your API key and project name are set correctly, tracking will work properly.\n",
    "\n",
    "However, if you want to change the project name or change the tracking, you can do so with the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "#s.environ[\"LANGCHAIN_PROJECT\"] = \"<LangChain Project Name>\"\n",
    "#s.environ[\"LANGCHAIN_API_KEY\"] = \"<LangChain API KEY>\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practical Example: Tracking a Simple RAG System\n",
    "\n",
    "Now that we have LangSmith configured, let's see it in action with a real RAG (Retrieval-Augmented Generation) system. This example is based on the simple RAG from notebook 07.\n",
    "\n",
    "We'll build a basic RAG pipeline and use LangSmith to:\n",
    "- **Trace** each step (document loading, splitting, retrieval, generation)\n",
    "- **Monitor** performance and token usage\n",
    "- **Debug** by inspecting retrieved documents and prompts\n",
    "- **Evaluate** response quality over multiple queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Install Required Packages\n",
    "\n",
    "First, let's install the packages we need for our RAG system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.3\n",
      "[notice] To update, run: C:\\Users\\FKY\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install -q langchain_mistralai langchain_community langchain_text_splitters langchain_core faiss-cpu pymupdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Build a Simple RAG Pipeline\n",
    "\n",
    "We'll create a basic RAG system that loads the ECAM regulation PDF, splits it into chunks, creates embeddings, and answers questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Loaded 61 pages from PDF\n",
      "‚úì Split into 497 chunks\n",
      "Loading existing FAISS store...\n",
      "\n",
      "‚úì RAG pipeline created and ready!\n",
      "  All operations will be traced in LangSmith automatically.\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_mistralai import ChatMistralAI, MistralAIEmbeddings\n",
    "\n",
    "# Step 1: Load Documents\n",
    "loader = PyMuPDFLoader(\"R√©glementECAM.pdf\")\n",
    "docs = loader.load()\n",
    "print(f\"‚úì Loaded {len(docs)} pages from PDF\")\n",
    "\n",
    "# Step 2: Split Documents\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "split_documents = text_splitter.split_documents(docs)\n",
    "print(f\"‚úì Split into {len(split_documents)} chunks\")\n",
    "\n",
    "# Step 3: Generate Embeddings and Create Vector Store\n",
    "embeddings = MistralAIEmbeddings(model=\"mistral-embed\")\n",
    "STORE_DIR = 'faiss_store'\n",
    "if os.path.isdir(STORE_DIR):\n",
    "    print('Loading existing FAISS store...')\n",
    "    vectorstore = FAISS.load_local(STORE_DIR, embeddings, allow_dangerous_deserialization=True)\n",
    "else:\n",
    "    print('Creating new FAISS store and saving...')\n",
    "    vectorstore = FAISS.from_documents(split_docs, embeddings)\n",
    "    vectorstore.save_local(STORE_DIR)\n",
    "\n",
    "# Step 4: Create Retriever\n",
    "retriever = vectorstore.as_retriever(search_kwargs={'k': 3})\n",
    "\n",
    "# Step 5: Create Prompt\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"You are an assistant for the school ECAM-ICHEC-ISFSC for question-answering tasks. \n",
    "Use the following pieces of retrieved context to answer the question. \n",
    "If you don't know the answer, just say that you don't know. \n",
    "\n",
    "#Context: \n",
    "{context}\n",
    "\n",
    "#Question:\n",
    "{question}\n",
    "\n",
    "#Answer:\"\"\"\n",
    ")\n",
    "\n",
    "# Step 6: Setup LLM\n",
    "llm = ChatMistralAI(model=\"mistral-small-latest\", temperature=0)\n",
    "\n",
    "# Step 7: Create RAG Chain (This will be automatically traced by LangSmith!)\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()} \n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(\"\\n‚úì RAG pipeline created and ready!\")\n",
    "print(\"  All operations will be traced in LangSmith automatically.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Test the RAG with LangSmith Tracing\n",
    "\n",
    "Now let's run some queries. **Each query will be automatically traced in LangSmith!**\n",
    "\n",
    "Go to your LangSmith dashboard at https://smith.langchain.com to see the traces in real-time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running queries with LangSmith tracing enabled...\n",
      "======================================================================\n",
      "\n",
      "üìù Question 1: Qu'est-ce que la financabilit√© d'un √©tudiant?\n",
      "----------------------------------------------------------------------\n",
      "ü§ñ Answer: La **finan√ßabilit√©** d'un √©tudiant fait r√©f√©rence √† l'√©ligibilit√© financi√®re pour b√©n√©ficier d'une aide ou d'un soutien financier de la part de la F√©d√©ration Wallonie-Bruxelles (ou d'autres instances)...\n",
      "\n",
      "\n",
      "üìù Question 2: Quelles sont les sanctions pour le plagiat?\n",
      "----------------------------------------------------------------------\n",
      "ü§ñ Answer: Les sanctions pour le plagiat √† l'ECAM-ICHEC-ISFSC incluent :\n",
      "\n",
      "1. **Sanction disciplinaire** : La Direction du D√©partement peut prononcer une sanction disciplinaire conform√©ment √† l'article 100 du r√®g...\n",
      "\n",
      "\n",
      "üìù Question 3: Comment cr√©er mon programme d'√©tude personnalis√©?\n",
      "----------------------------------------------------------------------\n",
      "ü§ñ Answer: Pour cr√©er votre programme d'√©tude personnalis√© √† l'ECAM-ICHEC-ISFSC, voici les √©tapes √† suivre selon le contexte fourni :\n",
      "\n",
      "1. **Composer votre programme** :\n",
      "   - Inclure les unit√©s d'enseignement de ...\n",
      "\n",
      "======================================================================\n",
      "‚úÖ All queries traced successfully!\n",
      "üîç Check your LangSmith dashboard to see:\n",
      "   - Retrieved documents for each query\n",
      "   - Complete prompt sent to the LLM\n",
      "   - Token usage and costs\n",
      "   - Execution time for each component\n",
      "\n",
      "üåê Dashboard: https://smith.langchain.com\n"
     ]
    }
   ],
   "source": [
    "# Test with several questions\n",
    "test_questions = [\n",
    "    \"Qu'est-ce que la financabilit√© d'un √©tudiant?\",\n",
    "    \"Quelles sont les sanctions pour le plagiat?\",\n",
    "    \"Comment cr√©er mon programme d'√©tude personnalis√©?\",\n",
    "]\n",
    "\n",
    "print(\"Running queries with LangSmith tracing enabled...\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for i, question in enumerate(test_questions, 1):\n",
    "    print(f\"\\nüìù Question {i}: {question}\")\n",
    "    print(\"-\"*70)\n",
    "    \n",
    "    response = rag_chain.invoke(question)\n",
    "    print(f\"ü§ñ Answer: {response[:200]}...\")\n",
    "    print()\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"‚úÖ All queries traced successfully!\")\n",
    "print(\"üîç Check your LangSmith dashboard to see:\")\n",
    "print(\"   - Retrieved documents for each query\")\n",
    "print(\"   - Complete prompt sent to the LLM\")\n",
    "print(\"   - Token usage and costs\")\n",
    "print(\"   - Execution time for each component\")\n",
    "print(f\"\\nüåê Dashboard: https://smith.langchain.com\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Understanding the LangSmith Trace\n",
    "\n",
    "When you look at a trace in LangSmith, you'll see:\n",
    "\n",
    "1. **Overall Execution**:\n",
    "   - Total time taken\n",
    "   - Total tokens used\n",
    "   - Cost estimation\n",
    "   - Success/Error status\n",
    "\n",
    "2. **Step-by-Step Breakdown**:\n",
    "   - **Retrieval**: Which documents were retrieved from the vector store\n",
    "   - **Prompt Construction**: The exact prompt sent to the LLM (with context)\n",
    "   - **LLM Call**: Input tokens, output tokens, model used\n",
    "   - **Output Parsing**: Final formatted response\n",
    "\n",
    "3. **Metadata**:\n",
    "   - Timestamp\n",
    "   - Model version\n",
    "   - Tags and custom metadata (if added)\n",
    "\n",
    "   By exposing each component‚Äôs inputs, outputs, timings, and token usage, the trace lets you quickly debug incorrect answers, optimize slow or costly steps, monitor performance and spend over time, and iteratively improve quality by comparing different prompts, models, or retrieval settings side‚Äëby‚Äëside."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5:Controlling Tracing\n",
    "\n",
    "Sometimes you may want to temporarily disable or re-enable tracing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1Ô∏è‚É£ Disabling tracing...\n",
      "   Response (NOT traced): Une **unit√© d‚Äôenseignement (UE)** est un √©l√©ment constitutif d'un programme d'√©t...\n",
      "\n",
      "2Ô∏è‚É£ Re-enabling tracing...\n",
      "   Response (TRACED): D'apr√®s le contexte fourni, \"AA\" n'est pas explicitement d√©fini. Cependant, dans...\n",
      "\n",
      "‚úÖ Tracing control demonstrated!\n",
      "\n",
      "üí° Use cases for disabling tracing:\n",
      "   - High-volume production queries (to reduce overhead)\n",
      "   - Privacy-sensitive queries\n",
      "   - Performance testing without observability overhead\n",
      "   - Development/testing scenarios\n"
     ]
    }
   ],
   "source": [
    "# Disable tracing\n",
    "print(\"1Ô∏è‚É£ Disabling tracing...\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"false\"\n",
    "\n",
    "response = rag_chain.invoke(\"Qu'est-ce qu'une UE?\")\n",
    "print(f\"   Response (NOT traced): {response[:80]}...\\n\")\n",
    "\n",
    "# Re-enable tracing\n",
    "print(\"2Ô∏è‚É£ Re-enabling tracing...\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "\n",
    "response = rag_chain.invoke(\"Qu'est-ce qu'une AA?\")\n",
    "print(f\"   Response (TRACED): {response[:80]}...\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
