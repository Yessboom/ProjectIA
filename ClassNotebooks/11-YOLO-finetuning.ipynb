{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e16144bf",
   "metadata": {},
   "source": [
    "# YOLOv8 Fine-tuning Tutorial\n",
    "\n",
    "This notebook demonstrates how to fine-tune a YOLOv8 model using the Ultralytics library with a local dataset composed of images of men and woman. The dataset of only 39 images and a light training already shows noticable capabilities.\n",
    "\n",
    "## Overview\n",
    "- Install required libraries\n",
    "- Load local dataset in YOLO format\n",
    "- Configure YOLOv8 for training\n",
    "- Train the model\n",
    "- Evaluate and test predictions\n",
    "- Export the fine-tuned model\n",
    "\n",
    "## Prerequisites\n",
    "- Python 3.8+\n",
    "- CUDA-compatible GPU (recommended for faster training but not a requirement)\n",
    "- Local dataset in YOLO format (images + labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cbfea9a",
   "metadata": {},
   "source": [
    "## Introduction to YOLO (You Only Look Once)\n",
    "\n",
    "**YOLO (You Only Look Once)** is a real-time object detection algorithm that approaches detection as a single regression problem. Unlike traditional methods that apply classifiers to different regions multiple times, YOLO processes the entire image in one forward pass, predicting bounding boxes, class probabilities simultaneously or segmenting the image.\n",
    "\n",
    "![YOLO Architecture](https://user-images.githubusercontent.com/26833433/212094133-6bb8c21c-3d47-41df-a512-81c5931054ae.png)\n",
    "\n",
    "The algorithm divides the input image into a grid system where each cell predicts bounding boxes and confidence scores. This single-pass architecture enables processing speeds of up to 100+ frames per second depending on the model variant and hardware, making it suitable for real-time applications.\n",
    "\n",
    "**YOLOv8**, developed by Ultralytics, is the latest iteration in the YOLO family. It features an anchor-free design, updated data augmentation techniques, and modified loss functions. The architecture provides multiple model sizes from nano to extra-large, allowing users to select between speed and accuracy based on their requirements.\n",
    "\n",
    "YOLO is applied across various domains including autonomous vehicles for obstacle detection, surveillance systems for monitoring, sports analytics for tracking, medical imaging for diagnosis assistance, retail automation for inventory management, and wildlife monitoring for conservation purposes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b702d8a",
   "metadata": {},
   "source": [
    "## 1. Install Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39adf22b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.5.1+cpu\n",
      "CUDA available: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.3\n",
      "[notice] To update, run: C:\\Users\\FKY\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Install Ultralytics (YOLOv8) and other dependencies\n",
    "!pip install ultralytics pillow pyyaml matplotlib opencv-python -q\n",
    "\n",
    "# Import necessary libraries\n",
    "import os\n",
    "from pathlib import Path\n",
    "from ultralytics import YOLO\n",
    "import torch\n",
    "import yaml\n",
    "from PIL import Image\n",
    "import shutil\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672819da",
   "metadata": {},
   "source": [
    "## 2. Load Local Dataset\n",
    "\n",
    "We'll use the local \"dataset HF\" folder which contains:\n",
    "- Images (.jpeg files)\n",
    "- Labels (.txt files in YOLO format: `class_id center_x center_y width height`, all normalized to 0-1)\n",
    "- classes.txt (list of class names)\n",
    "\n",
    "Make sure your dataset folder is in the same directory as this notebook.\n",
    "\n",
    "You can annotate your own images with many different, I used https://www.yololabellingtool.com/ to annotate this dataset, take a look a it and **try to annotate one or multiple images before continuing the notebook**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00285a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using local dataset: c:\\Users\\FKY\\OneDrive - ECAM\\Documents\\Cours\\Q1\\Projet IA\\2025-2026\\LangChain-OpenTutorial\\ECAM_Custom\\dataset HF\n",
      "✓ Classes found: ['homme', 'femme']\n",
      "✓ Number of classes: 2\n",
      "✓ Total images found: 39\n",
      "✓ Total label files found: 39\n"
     ]
    }
   ],
   "source": [
    "# Configuration - Using local \"dataset HF\" folder\n",
    "DATASET_HF_PATH = Path(\"dataset HF\")\n",
    "PROJECT_DIR = Path(\"./yolo_finetuning\")\n",
    "DATASET_DIR = PROJECT_DIR / \"dataset\"\n",
    "\n",
    "# Create directories\n",
    "PROJECT_DIR.mkdir(exist_ok=True)\n",
    "DATASET_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"Using local dataset: {DATASET_HF_PATH.absolute()}\")\n",
    "\n",
    "# Read class names from the local dataset\n",
    "classes_file = DATASET_HF_PATH / \"classes.txt\"\n",
    "if classes_file.exists():\n",
    "    with open(classes_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        class_names = [line.strip() for line in f.readlines()]\n",
    "    print(f\"✓ Classes found: {class_names}\")\n",
    "    print(f\"✓ Number of classes: {len(class_names)}\")\n",
    "else:\n",
    "    print(f\"⚠️ classes.txt not found at {classes_file}\")\n",
    "    class_names = []\n",
    "\n",
    "# Count files in the dataset\n",
    "image_files = list(DATASET_HF_PATH.glob(\"*.jpeg\")) + list(DATASET_HF_PATH.glob(\"*.jpg\"))\n",
    "label_files = [f for f in DATASET_HF_PATH.glob(\"*.txt\") if f.name != \"classes.txt\"]\n",
    "\n",
    "print(f\"✓ Total images found: {len(image_files)}\")\n",
    "print(f\"✓ Total label files found: {len(label_files)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a679f453",
   "metadata": {},
   "source": [
    "## 3. Prepare Dataset in YOLO Format\n",
    "\n",
    "YOLOv8 requires datasets in a specific format:\n",
    "```\n",
    "dataset/\n",
    "├── train/\n",
    "│   ├── images/\n",
    "│   └── labels/\n",
    "├── valid/\n",
    "│   ├── images/\n",
    "│   └── labels/\n",
    "└── data.yaml\n",
    "```\n",
    "\n",
    "Labels should be in YOLO format: `class_id center_x center_y width height` (normalized 0-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c770e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting dataset: 31 train, 8 validation\n",
      "✓ Dataset prepared successfully!\n",
      "  Train: 31 images\n",
      "  Valid: 8 images\n",
      "✓ Dataset prepared successfully!\n",
      "  Train: 31 images\n",
      "  Valid: 8 images\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def prepare_yolo_dataset_from_local(source_dir, output_dir, split_ratio=0.8):\n",
    "    \"\"\"\n",
    "    Prepare YOLO dataset from local folder\n",
    "    Split into train and validation sets\n",
    "    \"\"\"\n",
    "    # Create directory structure\n",
    "    train_images_dir = output_dir / \"train\" / \"images\"\n",
    "    train_labels_dir = output_dir / \"train\" / \"labels\"\n",
    "    val_images_dir = output_dir / \"valid\" / \"images\"\n",
    "    val_labels_dir = output_dir / \"valid\" / \"labels\"\n",
    "    \n",
    "    for dir_path in [train_images_dir, train_labels_dir, val_images_dir, val_labels_dir]:\n",
    "        dir_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Get all image files\n",
    "    image_files = list(source_dir.glob(\"*.jpeg\")) + list(source_dir.glob(\"*.jpg\"))\n",
    "    \n",
    "    # Shuffle and split\n",
    "    random.seed(42)\n",
    "    random.shuffle(image_files)\n",
    "    split_idx = int(len(image_files) * split_ratio)\n",
    "    \n",
    "    train_files = image_files[:split_idx]\n",
    "    val_files = image_files[split_idx:]\n",
    "    \n",
    "    print(f\"Splitting dataset: {len(train_files)} train, {len(val_files)} validation\")\n",
    "    \n",
    "    # Copy train files\n",
    "    for img_file in train_files:\n",
    "        label_file = img_file.with_suffix('.txt')\n",
    "        \n",
    "        # Copy image\n",
    "        shutil.copy(img_file, train_images_dir / img_file.name)\n",
    "        \n",
    "        # Copy label if exists\n",
    "        if label_file.exists():\n",
    "            shutil.copy(label_file, train_labels_dir / label_file.name)\n",
    "    \n",
    "    # Copy validation files\n",
    "    for img_file in val_files:\n",
    "        label_file = img_file.with_suffix('.txt')\n",
    "        \n",
    "        # Copy image\n",
    "        shutil.copy(img_file, val_images_dir / img_file.name)\n",
    "        \n",
    "        # Copy label if exists\n",
    "        if label_file.exists():\n",
    "            shutil.copy(label_file, val_labels_dir / label_file.name)\n",
    "    \n",
    "    print(f\"✓ Dataset prepared successfully!\")\n",
    "    print(f\"  Train: {len(list(train_images_dir.glob('*')))} images\")\n",
    "    print(f\"  Valid: {len(list(val_images_dir.glob('*')))} images\")\n",
    "    \n",
    "    return train_images_dir, val_images_dir\n",
    "\n",
    "# Prepare the dataset\n",
    "train_img_dir, val_img_dir = prepare_yolo_dataset_from_local(DATASET_HF_PATH, DATASET_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0beb0833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset structure verification:\n",
      "  Train images: yolo_finetuning\\dataset\\train\\images\n",
      "  Train labels: yolo_finetuning\\dataset\\train\\labels\n",
      "  Valid images: yolo_finetuning\\dataset\\valid\\images\n",
      "  Valid labels: yolo_finetuning\\dataset\\valid\\labels\n",
      "\n",
      "✓ Files in dataset:\n",
      "  Training: 31 images, 31 labels\n",
      "  Validation: 8 images, 8 labels\n"
     ]
    }
   ],
   "source": [
    "# Verify the dataset structure\n",
    "print(\"Dataset structure verification:\")\n",
    "print(f\"  Train images: {DATASET_DIR / 'train' / 'images'}\")\n",
    "print(f\"  Train labels: {DATASET_DIR / 'train' / 'labels'}\")\n",
    "print(f\"  Valid images: {DATASET_DIR / 'valid' / 'images'}\")\n",
    "print(f\"  Valid labels: {DATASET_DIR / 'valid' / 'labels'}\")\n",
    "\n",
    "# Count files\n",
    "train_imgs = len(list((DATASET_DIR / 'train' / 'images').glob('*')))\n",
    "train_lbls = len(list((DATASET_DIR / 'train' / 'labels').glob('*')))\n",
    "val_imgs = len(list((DATASET_DIR / 'valid' / 'images').glob('*')))\n",
    "val_lbls = len(list((DATASET_DIR / 'valid' / 'labels').glob('*')))\n",
    "\n",
    "print(f\"\\n✓ Files in dataset:\")\n",
    "print(f\"  Training: {train_imgs} images, {train_lbls} labels\")\n",
    "print(f\"  Validation: {val_imgs} images, {val_lbls} labels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44e633f",
   "metadata": {},
   "source": [
    "## 4. Create data.yaml Configuration File\n",
    "\n",
    "The `data.yaml` file tells YOLOv8 where to find the dataset and what classes exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f20c6391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Configuration saved to: yolo_finetuning\\dataset\\data.yaml\n",
      "\n",
      "Dataset configuration:\n",
      "names:\n",
      "- homme\n",
      "- femme\n",
      "nc: 2\n",
      "path: c:\\Users\\FKY\\OneDrive - ECAM\\Documents\\Cours\\Q1\\Projet IA\\2025-2026\\LangChain-OpenTutorial\\ECAM_Custom\\yolo_finetuning\\dataset\n",
      "train: train/images\n",
      "val: valid/images\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define your dataset configuration using the local dataset\n",
    "data_config = {\n",
    "    'path': str(DATASET_DIR.absolute()),  # Root directory\n",
    "    'train': 'train/images',  # Path to training images\n",
    "    'val': 'valid/images',    # Path to validation images\n",
    "    'nc': len(class_names),   # Number of classes from classes.txt\n",
    "    'names': class_names      # Class names from classes.txt\n",
    "}\n",
    "\n",
    "# Save configuration to YAML file\n",
    "yaml_path = DATASET_DIR / 'data.yaml'\n",
    "with open(yaml_path, 'w', encoding='utf-8') as f:\n",
    "    yaml.dump(data_config, f, default_flow_style=False, allow_unicode=True)\n",
    "\n",
    "print(f\"✓ Configuration saved to: {yaml_path}\")\n",
    "print(\"\\nDataset configuration:\")\n",
    "print(yaml.dump(data_config, default_flow_style=False, allow_unicode=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9803c522",
   "metadata": {},
   "source": [
    "## 5. Load Pre-trained YOLOv8 Model\n",
    "\n",
    "YOLOv8 comes in different sizes:\n",
    "- `yolov8n.pt` - Nano (fastest, least accurate)\n",
    "- `yolov8s.pt` - Small\n",
    "- `yolov8m.pt` - Medium\n",
    "- `yolov8l.pt` - Large\n",
    "- `yolov8x.pt` - Extra Large (slowest, most accurate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df235457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n.pt to 'yolov8n.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6.25M/6.25M [00:00<00:00, 18.9MB/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n",
      "Model type: <class 'ultralytics.models.yolo.model.YOLO'>\n",
      "YOLOv8n summary: 225 layers, 3,157,200 parameters, 0 gradients, 8.9 GFLOPs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(225, 3157200, 0, 8.8575488)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load a pre-trained YOLOv8 model\n",
    "# Start with yolov8n (nano) for faster training, or use yolov8m/yolov8l for better accuracy\n",
    "model = YOLO('yolov8n.pt')  # Automatically downloads if not present\n",
    "\n",
    "print(\"Model loaded successfully!\")\n",
    "print(f\"Model type: {type(model)}\")\n",
    "\n",
    "# Display model information\n",
    "model.info()  # Shows model architecture details"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640caac8",
   "metadata": {},
   "source": [
    "## 6. Train the Model\n",
    "\n",
    "Configure training parameters and start fine-tuning.\n",
    "\n",
    "### Key Training Parameters:\n",
    "- `data`: Path to data.yaml\n",
    "- `epochs`: Number of training epochs\n",
    "- `imgsz`: Image size (640 is standard)\n",
    "- `batch`: Batch size (adjust based on GPU memory)\n",
    "- `patience`: Early stopping patience\n",
    "- `lr0`: Initial learning rate\n",
    "- `device`: 'cuda' for GPU or 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76236ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training configuration:\n",
      "  data: yolo_finetuning\\dataset\\data.yaml\n",
      "  epochs: 50\n",
      "  imgsz: 640\n",
      "  batch: 16\n",
      "  patience: 10\n",
      "  save: True\n",
      "  device: cpu\n",
      "  project: yolo_finetuning\n",
      "  name: yolov8_custom\n",
      "  exist_ok: True\n",
      "  pretrained: True\n",
      "  optimizer: AdamW\n",
      "  lr0: 0.001\n",
      "  weight_decay: 0.0005\n",
      "  warmup_epochs: 3\n",
      "  augment: True\n",
      "  verbose: True\n",
      "\n",
      "⚠️ Note: Training may take several hours depending on dataset size and hardware!\n",
      "You can monitor progress in real-time through the console output.\n"
     ]
    }
   ],
   "source": [
    "# Training configuration\n",
    "training_args = {\n",
    "    'data': str(yaml_path),      # Path to data.yaml\n",
    "    'epochs': 50,                # Number of epochs (adjust based on dataset size)\n",
    "    'imgsz': 640,                # Image size\n",
    "    'batch': 16,                 # Batch size (reduce if GPU memory is limited)\n",
    "    'patience': 10,              # Early stopping patience\n",
    "    'save': True,                # Save checkpoints\n",
    "    'device': 0 if torch.cuda.is_available() else 'cpu',  # Use GPU if available\n",
    "    'project': str(PROJECT_DIR), # Project directory\n",
    "    'name': 'yolov8_custom',     # Experiment name\n",
    "    'exist_ok': True,            # Overwrite existing project\n",
    "    'pretrained': True,          # Use pretrained weights\n",
    "    'optimizer': 'AdamW',        # Optimizer (SGD, Adam, AdamW)\n",
    "    'lr0': 0.001,                # Initial learning rate\n",
    "    'weight_decay': 0.0005,      # Weight decay\n",
    "    'warmup_epochs': 3,          # Warmup epochs\n",
    "    'augment': True,             # Use data augmentation\n",
    "    'verbose': True,             # Verbose output\n",
    "}\n",
    "\n",
    "print(\"Training configuration:\")\n",
    "for key, value in training_args.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "print(\"\\n⚠️ Note: Training may take several hours depending on dataset size and hardware!\")\n",
    "print(\"You can monitor progress in real-time through the console output.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2bcb39cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.231 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.2.101  Python-3.12.10 torch-2.5.1+cpu CPU (AMD Ryzen 7 PRO 7840U w/ Radeon 780M Graphics)\n",
      "Ultralytics YOLOv8.2.101  Python-3.12.10 torch-2.5.1+cpu CPU (AMD Ryzen 7 PRO 7840U w/ Radeon 780M Graphics)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=yolo_finetuning\\dataset\\data.yaml, epochs=50, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=cpu, workers=8, project=yolo_finetuning, name=yolov8_custom, exist_ok=True, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=yolo_finetuning\\yolov8_custom\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=yolo_finetuning\\dataset\\data.yaml, epochs=50, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=cpu, workers=8, project=yolo_finetuning, name=yolov8_custom, exist_ok=True, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=yolo_finetuning\\yolov8_custom\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751702  ultralytics.nn.modules.head.Detect           [2, [64, 128, 256]]           \n",
      " 22        [15, 18, 21]  1    751702  ultralytics.nn.modules.head.Detect           [2, [64, 128, 256]]           \n",
      "Model summary: 225 layers, 3,011,238 parameters, 3,011,222 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Model summary: 225 layers, 3,011,238 parameters, 3,011,222 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolo_finetuning\\yolov8_custom', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolo_finetuning\\yolov8_custom', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\FKY\\OneDrive - ECAM\\Documents\\Cours\\Q1\\Projet IA\\2025-2026\\LangChain-OpenTutorial\\ECAM_Custom\\yolo_finetuning\\dataset\\train\\labels... 31 images, 0 backgrounds, 0 corrupt: 100%|██████████| 31/31 [00:00<00:00, 772.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: C:\\Users\\FKY\\OneDrive - ECAM\\Documents\\Cours\\Q1\\Projet IA\\2025-2026\\LangChain-OpenTutorial\\ECAM_Custom\\yolo_finetuning\\dataset\\train\\labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\FKY\\OneDrive - ECAM\\Documents\\Cours\\Q1\\Projet IA\\2025-2026\\LangChain-OpenTutorial\\ECAM_Custom\\yolo_finetuning\\dataset\\valid\\labels... 8 images, 0 backgrounds, 0 corrupt: 100%|██████████| 8/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\Users\\FKY\\OneDrive - ECAM\\Documents\\Cours\\Q1\\Projet IA\\2025-2026\\LangChain-OpenTutorial\\ECAM_Custom\\yolo_finetuning\\dataset\\valid\\labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to yolo_finetuning\\yolov8_custom\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added \n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1myolo_finetuning\\yolov8_custom\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added \n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1myolo_finetuning\\yolov8_custom\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/50         0G      1.454      2.802      1.689         64        640: 100%|██████████| 2/2 [00:05<00:00,  2.76s/it]\n",
      "       1/50         0G      1.454      2.802      1.689         64        640: 100%|██████████| 2/2 [00:05<00:00,  2.76s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          8         13    0.00576          1      0.484      0.291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/50         0G      1.534      2.813      1.774         60        640: 100%|██████████| 2/2 [00:04<00:00,  2.45s/it]\n",
      "       2/50         0G      1.534      2.813      1.774         60        640: 100%|██████████| 2/2 [00:04<00:00,  2.45s/it]/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          8         13    0.00573          1      0.515      0.297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/50         0G       1.58        2.8      1.811         58        640: 100%|██████████| 2/2 [00:05<00:00,  2.61s/it]\n",
      "       3/50         0G       1.58        2.8      1.811         58        640: 100%|██████████| 2/2 [00:05<00:00,  2.61s/it]/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          8         13    0.00557          1       0.53      0.303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/50         0G      1.443      2.631      1.743         67        640: 100%|██████████| 2/2 [00:05<00:00,  2.60s/it]\n",
      "       4/50         0G      1.443      2.631      1.743         67        640: 100%|██████████| 2/2 [00:05<00:00,  2.60s/it]/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          8         13    0.00503      0.944      0.559      0.317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/50         0G      1.383      2.477      1.572         79        640: 100%|██████████| 2/2 [00:05<00:00,  2.54s/it]\n",
      "       5/50         0G      1.383      2.477      1.572         79        640: 100%|██████████| 2/2 [00:05<00:00,  2.54s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          8         13    0.00498      0.944       0.59      0.335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/50         0G      1.439      2.252       1.63         68        640: 100%|██████████| 2/2 [00:04<00:00,  2.48s/it]\n",
      "       6/50         0G      1.439      2.252       1.63         68        640: 100%|██████████| 2/2 [00:04<00:00,  2.48s/it]/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          8         13      0.005      0.944      0.555       0.32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/50         0G       1.34      2.156      1.498         53        640: 100%|██████████| 2/2 [00:04<00:00,  2.42s/it]\n",
      "       7/50         0G       1.34      2.156      1.498         53        640: 100%|██████████| 2/2 [00:04<00:00,  2.42s/it]/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          8         13      0.005      0.944      0.551      0.324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/50         0G      1.286      1.954      1.481         59        640: 100%|██████████| 2/2 [00:05<00:00,  2.51s/it]\n",
      "       8/50         0G      1.286      1.954      1.481         59        640: 100%|██████████| 2/2 [00:05<00:00,  2.51s/it]/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          8         13    0.00538          1      0.612      0.373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/50         0G      1.252      1.778       1.47         58        640: 100%|██████████| 2/2 [00:04<00:00,  2.44s/it]\n",
      "       9/50         0G      1.252      1.778       1.47         58        640: 100%|██████████| 2/2 [00:04<00:00,  2.44s/it]/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          8         13    0.00536          1      0.621      0.395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/50         0G      1.202      1.731      1.362         62        640: 100%|██████████| 2/2 [00:04<00:00,  2.46s/it]\n",
      "      10/50         0G      1.202      1.731      1.362         62        640: 100%|██████████| 2/2 [00:04<00:00,  2.46s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          8         13    0.00536          1      0.607      0.385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/50         0G      1.162      1.748       1.43         57        640: 100%|██████████| 2/2 [00:04<00:00,  2.37s/it]\n",
      "      11/50         0G      1.162      1.748       1.43         57        640: 100%|██████████| 2/2 [00:04<00:00,  2.37s/it]/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          8         13    0.00495      0.944      0.639      0.422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/50         0G      1.156      1.674      1.353         71        640: 100%|██████████| 2/2 [00:04<00:00,  2.45s/it]\n",
      "      12/50         0G      1.156      1.674      1.353         71        640: 100%|██████████| 2/2 [00:04<00:00,  2.45s/it]/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          8         13    0.00535          1      0.646      0.423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/50         0G       1.11      1.663      1.322         64        640: 100%|██████████| 2/2 [00:04<00:00,  2.40s/it]\n",
      "      13/50         0G       1.11      1.663      1.322         64        640: 100%|██████████| 2/2 [00:04<00:00,  2.40s/it]/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          8         13    0.00495      0.944       0.69      0.439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/50         0G      1.151        1.6      1.417         59        640: 100%|██████████| 2/2 [00:04<00:00,  2.43s/it]\n",
      "      14/50         0G      1.151        1.6      1.417         59        640: 100%|██████████| 2/2 [00:04<00:00,  2.43s/it]/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          8         13    0.00538          1      0.667      0.442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/50         0G      1.172      1.579      1.367         68        640: 100%|██████████| 2/2 [00:04<00:00,  2.41s/it]\n",
      "      15/50         0G      1.172      1.579      1.367         68        640: 100%|██████████| 2/2 [00:04<00:00,  2.41s/it]/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          8         13      0.394      0.708      0.642      0.405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/50         0G      1.045       1.51      1.293         58        640: 100%|██████████| 2/2 [00:04<00:00,  2.39s/it]\n",
      "      16/50         0G      1.045       1.51      1.293         58        640: 100%|██████████| 2/2 [00:04<00:00,  2.39s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          8         13      0.759      0.138      0.701      0.452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/50         0G      1.039       1.46      1.263         76        640: 100%|██████████| 2/2 [00:04<00:00,  2.46s/it]\n",
      "      17/50         0G      1.039       1.46      1.263         76        640: 100%|██████████| 2/2 [00:04<00:00,  2.46s/it]/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          8         13      0.758      0.511      0.744      0.451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/50         0G      1.105       1.44      1.288         67        640: 100%|██████████| 2/2 [00:04<00:00,  2.39s/it]\n",
      "      18/50         0G      1.105       1.44      1.288         67        640: 100%|██████████| 2/2 [00:04<00:00,  2.39s/it]/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          8         13      0.701      0.593       0.75      0.433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/50         0G      1.045      1.357      1.266         69        640: 100%|██████████| 2/2 [00:04<00:00,  2.39s/it]\n",
      "      19/50         0G      1.045      1.357      1.266         69        640: 100%|██████████| 2/2 [00:04<00:00,  2.39s/it]/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          8         13      0.684      0.579      0.772      0.425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/50         0G      1.052      1.365      1.317         69        640: 100%|██████████| 2/2 [00:04<00:00,  2.36s/it]\n",
      "      20/50         0G      1.052      1.365      1.317         69        640: 100%|██████████| 2/2 [00:04<00:00,  2.36s/it]/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          8         13        0.9      0.554      0.791      0.459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      21/50         0G     0.9576      1.306      1.231         64        640: 100%|██████████| 2/2 [00:04<00:00,  2.37s/it]\n",
      "      21/50         0G     0.9576      1.306      1.231         64        640: 100%|██████████| 2/2 [00:04<00:00,  2.37s/it]/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          8         13      0.897      0.564      0.794      0.436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      22/50         0G     0.9956      1.346      1.278         51        640: 100%|██████████| 2/2 [00:04<00:00,  2.40s/it]\n",
      "      22/50         0G     0.9956      1.346      1.278         51        640: 100%|██████████| 2/2 [00:04<00:00,  2.40s/it]/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          8         13      0.904      0.523      0.794      0.447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      23/50         0G      0.911      1.212      1.193         63        640: 100%|██████████| 2/2 [00:06<00:00,  3.32s/it]\n",
      "      23/50         0G      0.911      1.212      1.193         63        640: 100%|██████████| 2/2 [00:06<00:00,  3.32s/it]/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          8         13      0.926      0.486      0.741      0.436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      24/50         0G      1.024       1.18      1.222         63        640: 100%|██████████| 2/2 [00:06<00:00,  3.35s/it]\n",
      "      24/50         0G      1.024       1.18      1.222         63        640: 100%|██████████| 2/2 [00:06<00:00,  3.35s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          8         13      0.878      0.481      0.683      0.395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      25/50         0G     0.8741      1.126      1.231         62        640: 100%|██████████| 2/2 [00:06<00:00,  3.43s/it]\n",
      "      25/50         0G     0.8741      1.126      1.231         62        640: 100%|██████████| 2/2 [00:06<00:00,  3.43s/it]/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          8         13      0.669      0.486      0.661      0.348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      26/50         0G     0.9037      1.125      1.226         52        640: 100%|██████████| 2/2 [00:06<00:00,  3.10s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          8         13      0.775      0.653      0.666      0.322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      27/50         0G      1.005      1.148      1.245         61        640: 100%|██████████| 2/2 [00:06<00:00,  3.25s/it]\n",
      "      27/50         0G      1.005      1.148      1.245         61        640: 100%|██████████| 2/2 [00:06<00:00,  3.25s/it]/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          8         13      0.817      0.637      0.704      0.322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      28/50         0G     0.8521      1.108      1.159         64        640: 100%|██████████| 2/2 [00:06<00:00,  3.10s/it]\n",
      "      28/50         0G     0.8521      1.108      1.159         64        640: 100%|██████████| 2/2 [00:06<00:00,  3.10s/it]/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          8         13      0.817      0.637      0.704      0.322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      29/50         0G     0.8515      1.028      1.163         72        640: 100%|██████████| 2/2 [00:06<00:00,  3.10s/it]\n",
      "      29/50         0G     0.8515      1.028      1.163         72        640: 100%|██████████| 2/2 [00:06<00:00,  3.10s/it]/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          8         13      0.798      0.679      0.713      0.383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      30/50         0G     0.8712      1.067      1.205         62        640: 100%|██████████| 2/2 [00:06<00:00,  3.10s/it]\n",
      "      30/50         0G     0.8712      1.067      1.205         62        640: 100%|██████████| 2/2 [00:06<00:00,  3.10s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          8         13       0.84      0.724      0.779      0.447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      31/50         0G     0.9904      1.094      1.253         62        640: 100%|██████████| 2/2 [00:06<00:00,  3.04s/it]\n",
      "      31/50         0G     0.9904      1.094      1.253         62        640: 100%|██████████| 2/2 [00:06<00:00,  3.04s/it]/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          8         13       0.84      0.724      0.779      0.447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      32/50         0G     0.9072      1.105      1.228         61        640: 100%|██████████| 2/2 [00:06<00:00,  3.07s/it]\n",
      "      32/50         0G     0.9072      1.105      1.228         61        640: 100%|██████████| 2/2 [00:06<00:00,  3.07s/it]/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          8         13      0.958      0.633      0.801      0.477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      33/50         0G     0.8973      1.079      1.174         67        640: 100%|██████████| 2/2 [00:06<00:00,  3.05s/it]\n",
      "      33/50         0G     0.8973      1.079      1.174         67        640: 100%|██████████| 2/2 [00:06<00:00,  3.05s/it]/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          8         13      0.744      0.653      0.766      0.443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      34/50         0G     0.8877      1.096      1.211         70        640: 100%|██████████| 2/2 [00:06<00:00,  3.04s/it]\n",
      "      34/50         0G     0.8877      1.096      1.211         70        640: 100%|██████████| 2/2 [00:06<00:00,  3.04s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          8         13      0.744      0.653      0.766      0.443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      35/50         0G     0.8859      1.132      1.202         59        640: 100%|██████████| 2/2 [00:06<00:00,  3.08s/it]\n",
      "      35/50         0G     0.8859      1.132      1.202         59        640: 100%|██████████| 2/2 [00:06<00:00,  3.08s/it]/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          8         13       0.74      0.708      0.744      0.446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      36/50         0G     0.7754      1.059      1.121         75        640: 100%|██████████| 2/2 [00:06<00:00,  3.07s/it]\n",
      "      36/50         0G     0.7754      1.059      1.121         75        640: 100%|██████████| 2/2 [00:06<00:00,  3.07s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          8         13      0.786      0.708      0.768      0.453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      37/50         0G     0.8354      0.996      1.159         69        640: 100%|██████████| 2/2 [00:06<00:00,  3.07s/it]\n",
      "      37/50         0G     0.8354      0.996      1.159         69        640: 100%|██████████| 2/2 [00:06<00:00,  3.07s/it]/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          8         13      0.786      0.708      0.768      0.453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      38/50         0G     0.8176      1.045      1.168         64        640: 100%|██████████| 2/2 [00:06<00:00,  3.10s/it]\n",
      "      38/50         0G     0.8176      1.045      1.168         64        640: 100%|██████████| 2/2 [00:06<00:00,  3.10s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          8         13      0.823      0.814      0.769      0.463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      39/50         0G     0.8028      1.067      1.211         63        640: 100%|██████████| 2/2 [00:06<00:00,  3.03s/it]\n",
      "      39/50         0G     0.8028      1.067      1.211         63        640: 100%|██████████| 2/2 [00:06<00:00,  3.03s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          8         13      0.848      0.778      0.788      0.467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      40/50         0G     0.7027     0.9243      1.045         58        640: 100%|██████████| 2/2 [00:06<00:00,  3.02s/it]\n",
      "      40/50         0G     0.7027     0.9243      1.045         58        640: 100%|██████████| 2/2 [00:06<00:00,  3.02s/it]/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          8         13      0.848      0.778      0.788      0.467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      41/50         0G     0.6895      1.256      1.192         31        640: 100%|██████████| 2/2 [00:06<00:00,  3.01s/it]\n",
      "      41/50         0G     0.6895      1.256      1.192         31        640: 100%|██████████| 2/2 [00:06<00:00,  3.01s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          8         13       0.77       0.71      0.757      0.462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      42/50         0G     0.6457      1.228      1.107         24        640: 100%|██████████| 2/2 [00:06<00:00,  3.03s/it]\n",
      "      42/50         0G     0.6457      1.228      1.107         24        640: 100%|██████████| 2/2 [00:06<00:00,  3.03s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          8         13       0.78      0.653      0.729      0.426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      43/50         0G     0.7018      1.214      1.137         27        640: 100%|██████████| 2/2 [00:05<00:00,  2.99s/it]\n",
      "      43/50         0G     0.7018      1.214      1.137         27        640: 100%|██████████| 2/2 [00:05<00:00,  2.99s/it]/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          8         13       0.78      0.653      0.729      0.426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      44/50         0G     0.7244      1.208       1.13         30        640: 100%|██████████| 2/2 [00:05<00:00,  2.98s/it]\n",
      "      44/50         0G     0.7244      1.208       1.13         30        640: 100%|██████████| 2/2 [00:05<00:00,  2.98s/it]/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          8         13      0.823      0.646      0.719      0.417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      45/50         0G     0.6305       1.13       1.05         25        640: 100%|██████████| 2/2 [00:05<00:00,  2.97s/it]\n",
      "      45/50         0G     0.6305       1.13       1.05         25        640: 100%|██████████| 2/2 [00:05<00:00,  2.97s/it]/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          8         13      0.823      0.646      0.719      0.417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      46/50         0G     0.6085      1.196        1.1         31        640: 100%|██████████| 2/2 [00:06<00:00,  3.03s/it]\n",
      "      46/50         0G     0.6085      1.196        1.1         31        640: 100%|██████████| 2/2 [00:06<00:00,  3.03s/it]/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          8         13      0.828      0.653      0.717      0.408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      47/50         0G     0.6235      1.131      1.078         28        640: 100%|██████████| 2/2 [00:06<00:00,  3.03s/it]\n",
      "      47/50         0G     0.6235      1.131      1.078         28        640: 100%|██████████| 2/2 [00:06<00:00,  3.03s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          8         13      0.828      0.653      0.717      0.408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      48/50         0G     0.6332       1.12      1.063         27        640: 100%|██████████| 2/2 [00:06<00:00,  3.00s/it]\n",
      "      48/50         0G     0.6332       1.12      1.063         27        640: 100%|██████████| 2/2 [00:06<00:00,  3.00s/it]/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          8         13      0.791      0.653      0.721      0.418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      49/50         0G      0.599      1.106      1.078         24        640: 100%|██████████| 2/2 [00:05<00:00,  2.97s/it]\n",
      "      49/50         0G      0.599      1.106      1.078         24        640: 100%|██████████| 2/2 [00:05<00:00,  2.97s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          8         13      0.791      0.653      0.721      0.418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      50/50         0G     0.6202      1.136      1.085         25        640: 100%|██████████| 2/2 [00:05<00:00,  3.00s/it]\n",
      "      50/50         0G     0.6202      1.136      1.085         25        640: 100%|██████████| 2/2 [00:05<00:00,  3.00s/it]/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          8         13      0.812      0.653      0.721      0.418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "50 epochs completed in 0.098 hours.\n",
      "Optimizer stripped from yolo_finetuning\\yolov8_custom\\weights\\last.pt, 6.2MB\n",
      "Optimizer stripped from yolo_finetuning\\yolov8_custom\\weights\\last.pt, 6.2MB\n",
      "Optimizer stripped from yolo_finetuning\\yolov8_custom\\weights\\best.pt, 6.2MB\n",
      "\n",
      "Validating yolo_finetuning\\yolov8_custom\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.2.101  Python-3.12.10 torch-2.5.1+cpu CPU (AMD Ryzen 7 PRO 7840U w/ Radeon 780M Graphics)\n",
      "Optimizer stripped from yolo_finetuning\\yolov8_custom\\weights\\best.pt, 6.2MB\n",
      "\n",
      "Validating yolo_finetuning\\yolov8_custom\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.2.101  Python-3.12.10 torch-2.5.1+cpu CPU (AMD Ryzen 7 PRO 7840U w/ Radeon 780M Graphics)\n",
      "Model summary (fused): 168 layers, 3,006,038 parameters, 0 gradients, 8.1 GFLOPs\n",
      "Model summary (fused): 168 layers, 3,006,038 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.16it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          8         13      0.956      0.632      0.801      0.477\n",
      "                 homme          7          9      0.912      0.556      0.745      0.478\n",
      "                 femme          4          4          1      0.709      0.856      0.476\n",
      "                 homme          7          9      0.912      0.556      0.745      0.478\n",
      "                 femme          4          4          1      0.709      0.856      0.476\n",
      "Speed: 1.1ms preprocess, 60.4ms inference, 0.0ms loss, 34.3ms postprocess per image\n",
      "Results saved to \u001b[1myolo_finetuning\\yolov8_custom\u001b[0m\n",
      "Speed: 1.1ms preprocess, 60.4ms inference, 0.0ms loss, 34.3ms postprocess per image\n",
      "Results saved to \u001b[1myolo_finetuning\\yolov8_custom\u001b[0m\n",
      "✓ Training completed!\n",
      "Results saved to: yolo_finetuning\\yolov8_custom\n",
      "✓ Training completed!\n",
      "Results saved to: yolo_finetuning\\yolov8_custom\n"
     ]
    }
   ],
   "source": [
    "# Start training with the local dataset\n",
    "# Uncomment the following lines when you're ready to train\n",
    "results = model.train(\n",
    "    data=str(yaml_path),\n",
    "    epochs=50,\n",
    "    imgsz=640,\n",
    "    batch=16,\n",
    "    device=0 if torch.cuda.is_available() else 'cpu',\n",
    "    project=str(PROJECT_DIR),\n",
    "    name='yolov8_custom',\n",
    "    exist_ok=True\n",
    ")\n",
    "\n",
    "print(\"✓ Training completed!\")\n",
    "print(f\"Results saved to: {PROJECT_DIR / 'yolov8_custom'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44740eb1",
   "metadata": {},
   "source": [
    "## 7. Evaluate the Model\n",
    "\n",
    "After training, evaluate the model's performance on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "75970bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded fine-tuned model from: yolo_finetuning\\yolov8_custom\\weights\\best.pt\n",
      "Ultralytics YOLOv8.2.101  Python-3.12.10 torch-2.5.1+cpu CPU (AMD Ryzen 7 PRO 7840U w/ Radeon 780M Graphics)\n",
      "Model summary (fused): 168 layers, 3,006,038 parameters, 0 gradients, 8.1 GFLOPs\n",
      "Model summary (fused): 168 layers, 3,006,038 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\FKY\\OneDrive - ECAM\\Documents\\Cours\\Q1\\Projet IA\\2025-2026\\LangChain-OpenTutorial\\ECAM_Custom\\yolo_finetuning\\dataset\\valid\\labels.cache... 8 images, 0 backgrounds, 0 corrupt: 100%|██████████| 8/8 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.42it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          8         13      0.956      0.632      0.801      0.477\n",
      "                 homme          7          9      0.912      0.556      0.745      0.478\n",
      "                 femme          4          4          1      0.709      0.856      0.476\n",
      "                 homme          7          9      0.912      0.556      0.745      0.478\n",
      "                 femme          4          4          1      0.709      0.856      0.476\n",
      "Speed: 16.3ms preprocess, 41.8ms inference, 0.0ms loss, 22.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\val2\u001b[0m\n",
      "\n",
      "==================================================\n",
      "Validation Metrics\n",
      "==================================================\n",
      "mAP50: 0.8005\n",
      "mAP50-95: 0.4770\n",
      "Precision: 0.9561\n",
      "Recall: 0.6324\n",
      "==================================================\n",
      "Speed: 16.3ms preprocess, 41.8ms inference, 0.0ms loss, 22.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\val2\u001b[0m\n",
      "\n",
      "==================================================\n",
      "Validation Metrics\n",
      "==================================================\n",
      "mAP50: 0.8005\n",
      "mAP50-95: 0.4770\n",
      "Precision: 0.9561\n",
      "Recall: 0.6324\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Load the best trained model\n",
    "# After training, the best model is saved as 'best.pt'\n",
    "best_model_path = PROJECT_DIR / 'yolov8_custom' / 'weights' / 'best.pt'\n",
    "\n",
    "# Check if model exists\n",
    "if best_model_path.exists():\n",
    "    model = YOLO(str(best_model_path))\n",
    "    print(f\"Loaded fine-tuned model from: {best_model_path}\")\n",
    "    \n",
    "    # Validate the model on the validation set\n",
    "    metrics = model.val(data=str(yaml_path))\n",
    "    \n",
    "    # Display metrics\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Validation Metrics\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"mAP50: {metrics.box.map50:.4f}\")        # mAP at IoU=0.50\n",
    "    print(f\"mAP50-95: {metrics.box.map:.4f}\")       # mAP at IoU=0.50:0.95\n",
    "    print(f\"Precision: {metrics.box.mp:.4f}\")       # Mean precision\n",
    "    print(f\"Recall: {metrics.box.mr:.4f}\")          # Mean recall\n",
    "    print(\"=\"*50)\n",
    "else:\n",
    "    print(f\"Model not found at: {best_model_path}\")\n",
    "    print(\"Please train the model first!\")\n",
    "    print(\"\\nFor demonstration, you can load the pre-trained model:\")\n",
    "    model = YOLO('yolov8n.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae8c8f5",
   "metadata": {},
   "source": [
    "## 8. Make Predictions on New Images\n",
    "\n",
    "Test the fine-tuned model on the validation images. **Then check the result in the runs/detect/predict folders!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bd5ae5f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8 validation images\n",
      "Starting predictions on all validation images...\n",
      "\n",
      "\n",
      "image 1/8 c:\\Users\\FKY\\OneDrive - ECAM\\Documents\\Cours\\Q1\\Projet IA\\2025-2026\\LangChain-OpenTutorial\\ECAM_Custom\\yolo_finetuning\\dataset\\valid\\images\\OIP-1189158535.jpeg: 448x640 1 homme, 1 femme, 47.5ms\n",
      "image 1/8 c:\\Users\\FKY\\OneDrive - ECAM\\Documents\\Cours\\Q1\\Projet IA\\2025-2026\\LangChain-OpenTutorial\\ECAM_Custom\\yolo_finetuning\\dataset\\valid\\images\\OIP-1189158535.jpeg: 448x640 1 homme, 1 femme, 47.5ms\n",
      "image 2/8 c:\\Users\\FKY\\OneDrive - ECAM\\Documents\\Cours\\Q1\\Projet IA\\2025-2026\\LangChain-OpenTutorial\\ECAM_Custom\\yolo_finetuning\\dataset\\valid\\images\\OIP-1562483083.jpeg: 480x640 (no detections), 45.0ms\n",
      "image 2/8 c:\\Users\\FKY\\OneDrive - ECAM\\Documents\\Cours\\Q1\\Projet IA\\2025-2026\\LangChain-OpenTutorial\\ECAM_Custom\\yolo_finetuning\\dataset\\valid\\images\\OIP-1562483083.jpeg: 480x640 (no detections), 45.0ms\n",
      "image 3/8 c:\\Users\\FKY\\OneDrive - ECAM\\Documents\\Cours\\Q1\\Projet IA\\2025-2026\\LangChain-OpenTutorial\\ECAM_Custom\\yolo_finetuning\\dataset\\valid\\images\\OIP-1664498815.jpeg: 448x640 (no detections), 34.4ms\n",
      "image 3/8 c:\\Users\\FKY\\OneDrive - ECAM\\Documents\\Cours\\Q1\\Projet IA\\2025-2026\\LangChain-OpenTutorial\\ECAM_Custom\\yolo_finetuning\\dataset\\valid\\images\\OIP-1664498815.jpeg: 448x640 (no detections), 34.4ms\n",
      "image 4/8 c:\\Users\\FKY\\OneDrive - ECAM\\Documents\\Cours\\Q1\\Projet IA\\2025-2026\\LangChain-OpenTutorial\\ECAM_Custom\\yolo_finetuning\\dataset\\valid\\images\\OIP-1839275573.jpeg: 480x640 1 homme, 36.3ms\n",
      "image 4/8 c:\\Users\\FKY\\OneDrive - ECAM\\Documents\\Cours\\Q1\\Projet IA\\2025-2026\\LangChain-OpenTutorial\\ECAM_Custom\\yolo_finetuning\\dataset\\valid\\images\\OIP-1839275573.jpeg: 480x640 1 homme, 36.3ms\n",
      "image 5/8 c:\\Users\\FKY\\OneDrive - ECAM\\Documents\\Cours\\Q1\\Projet IA\\2025-2026\\LangChain-OpenTutorial\\ECAM_Custom\\yolo_finetuning\\dataset\\valid\\images\\OIP-2079919929.jpeg: 640x448 1 femme, 51.0ms\n",
      "image 5/8 c:\\Users\\FKY\\OneDrive - ECAM\\Documents\\Cours\\Q1\\Projet IA\\2025-2026\\LangChain-OpenTutorial\\ECAM_Custom\\yolo_finetuning\\dataset\\valid\\images\\OIP-2079919929.jpeg: 640x448 1 femme, 51.0ms\n",
      "image 6/8 c:\\Users\\FKY\\OneDrive - ECAM\\Documents\\Cours\\Q1\\Projet IA\\2025-2026\\LangChain-OpenTutorial\\ECAM_Custom\\yolo_finetuning\\dataset\\valid\\images\\OIP-2511001431.jpeg: 448x640 1 homme, 34.0ms\n",
      "image 6/8 c:\\Users\\FKY\\OneDrive - ECAM\\Documents\\Cours\\Q1\\Projet IA\\2025-2026\\LangChain-OpenTutorial\\ECAM_Custom\\yolo_finetuning\\dataset\\valid\\images\\OIP-2511001431.jpeg: 448x640 1 homme, 34.0ms\n",
      "image 7/8 c:\\Users\\FKY\\OneDrive - ECAM\\Documents\\Cours\\Q1\\Projet IA\\2025-2026\\LangChain-OpenTutorial\\ECAM_Custom\\yolo_finetuning\\dataset\\valid\\images\\OIP-2563531409.jpeg: 448x640 2 hommes, 38.5ms\n",
      "image 7/8 c:\\Users\\FKY\\OneDrive - ECAM\\Documents\\Cours\\Q1\\Projet IA\\2025-2026\\LangChain-OpenTutorial\\ECAM_Custom\\yolo_finetuning\\dataset\\valid\\images\\OIP-2563531409.jpeg: 448x640 2 hommes, 38.5ms\n",
      "image 8/8 c:\\Users\\FKY\\OneDrive - ECAM\\Documents\\Cours\\Q1\\Projet IA\\2025-2026\\LangChain-OpenTutorial\\ECAM_Custom\\yolo_finetuning\\dataset\\valid\\images\\OIP-2696330057.jpeg: 448x640 (no detections), 39.2ms\n",
      "Speed: 2.2ms preprocess, 40.7ms inference, 0.5ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict2\u001b[0m\n",
      "✓ Predictions complete for 8 images!\n",
      "Results saved to runs/detect/predict\n",
      "\n",
      "Summary:\n",
      "  Total images processed: 8\n",
      "  Total objects detected: 7\n",
      "  Average detections per image: 0.88\n",
      "image 8/8 c:\\Users\\FKY\\OneDrive - ECAM\\Documents\\Cours\\Q1\\Projet IA\\2025-2026\\LangChain-OpenTutorial\\ECAM_Custom\\yolo_finetuning\\dataset\\valid\\images\\OIP-2696330057.jpeg: 448x640 (no detections), 39.2ms\n",
      "Speed: 2.2ms preprocess, 40.7ms inference, 0.5ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict2\u001b[0m\n",
      "✓ Predictions complete for 8 images!\n",
      "Results saved to runs/detect/predict\n",
      "\n",
      "Summary:\n",
      "  Total images processed: 8\n",
      "  Total objects detected: 7\n",
      "  Average detections per image: 0.88\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on all validation images\n",
    "test_image_path = DATASET_DIR / 'valid' / 'images'\n",
    "\n",
    "# Get all validation images\n",
    "val_images_list = list(test_image_path.glob('*.jpeg')) + list(test_image_path.glob('*.jpg'))\n",
    "\n",
    "if val_images_list:\n",
    "    print(f\"Found {len(val_images_list)} validation images\")\n",
    "    print(\"Starting predictions on all validation images...\\n\")\n",
    "    \n",
    "    # Make predictions on all images at once\n",
    "    results = model.predict(\n",
    "        source=str(test_image_path),  # Pass the directory path\n",
    "        conf=0.25,          # Confidence threshold\n",
    "        iou=0.45,           # NMS IoU threshold\n",
    "        save=True,          # Save results to disk\n",
    "        show_labels=True,   # Show labels\n",
    "        show_conf=True,     # Show confidence scores\n",
    "        line_width=2,       # Line width of bounding boxes\n",
    "    )\n",
    "    \n",
    "    print(f\"✓ Predictions complete for {len(results)} images!\")\n",
    "    print(f\"Results saved to runs/detect/predict\")\n",
    "    \n",
    "    # Summary of detections\n",
    "    total_detections = sum(len(r.boxes) for r in results)\n",
    "    print(f\"\\nSummary:\")\n",
    "    print(f\"  Total images processed: {len(results)}\")\n",
    "    print(f\"  Total objects detected: {total_detections}\")\n",
    "    print(f\"  Average detections per image: {total_detections/len(results):.2f}\")\n",
    "else:\n",
    "    print(\"No validation images found!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119a403f",
   "metadata": {},
   "source": [
    "## 11. Training Tips & Best Practices\n",
    "\n",
    "### Dataset Preparation\n",
    "1. **Quality over Quantity**: Ensure your annotations are accurate\n",
    "2. **Balanced Classes**: Try to have roughly equal samples per class\n",
    "3. **Diverse Images**: Include various lighting, angles, and backgrounds\n",
    "4. **Data Augmentation**: YOLOv8 applies augmentation automatically\n",
    "\n",
    "### Training Optimization\n",
    "1. **Start Small**: Use `yolov8n` for quick experiments\n",
    "2. **Monitor Training**: Watch for overfitting (validation loss increasing)\n",
    "3. **Early Stopping**: Use patience parameter to stop when not improving\n",
    "4. **Learning Rate**: Start with default, adjust if needed\n",
    "5. **Batch Size**: Larger batch = more stable, but needs more GPU memory\n",
    "\n",
    "### Common Issues\n",
    "- **Low mAP**: More data, better annotations, longer training\n",
    "- **Overfitting**: More data augmentation, reduce epochs, add regularization\n",
    "- **Out of Memory**: Reduce batch size or image size\n",
    "- **Slow Training**: Use GPU, reduce image size, smaller model\n",
    "\n",
    "### Dataset Sources\n",
    "- **Roboflow Universe**: Pre-labeled datasets in YOLO format\n",
    "- **Hugging Face**: Various computer vision datasets\n",
    "- **COCO, Pascal VOC**: Standard benchmarks\n",
    "- **Custom**: Label your own with tools like LabelImg, CVAT, or Roboflow"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
