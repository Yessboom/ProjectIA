{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "805e7413",
   "metadata": {},
   "source": [
    "# Comprehensive Guide to Using Mistral AI with LangChain\n",
    "\n",
    "- Author: Martin Fockedey with the help of copilot\n",
    "- This is based on [LangChain Open Tutorial](https://github.com/LangChain-OpenTutorial/LangChain-OpenTutorial)\n",
    "\n",
    "## Overview\n",
    "\n",
    "This comprehensive tutorial demonstrates how to effectively use **Mistral AI models** with **LangChain**. You'll learn to:\n",
    "\n",
    "- Set up and configure Mistral AI chat models\n",
    "- Create and use prompt templates with Mistral\n",
    "- Build LCEL (LangChain Expression Language) chains\n",
    "- Implement streaming, batch processing, and async operations\n",
    "- Execute parallel chains for efficient processing\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "- [Overview](#overview)\n",
    "- [Environment Setup](#environment-setup)\n",
    "- [Mistral AI Models Overview](#mistral-ai-models-overview)\n",
    "- [Basic Usage of ChatMistralAI](#basic-usage-of-chatmistralai)\n",
    "- [Building Chains with LCEL](#building-chains-with-lcel)\n",
    "- [LCEL Interfaces](#lcel-interfaces)\n",
    "- [Parallel Execution](#parallel-execution)\n",
    "\n",
    "### References\n",
    "\n",
    "- [Mistral AI Documentation](https://docs.mistral.ai/)\n",
    "- [LangChain Mistral Integration](https://python.langchain.com/docs/integrations/chat/mistralai)\n",
    "- [LangChain Expression Language](https://python.langchain.com/docs/expression_language/)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c32f86a",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "Set up the environment.\n",
    "\n",
    "**[Note]**\n",
    "- You have one on your Teams group channel.\n",
    "- Store your API key in a `.env` file as `MISTRAL_API_KEY`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a199caf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.3\n",
      "[notice] To update, run: C:\\Users\\FKY\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install -q python-dotenv langchain_mistralai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "320744ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configuration file to manage the API KEY as an environment variable\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load API KEY information\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9771aae8",
   "metadata": {},
   "source": [
    "## LangChain\n",
    "We use LangChain because it provides a unified, modular framework for building complex AI applications that can **easily switch between different LLM providers without rewriting code**. It offers **powerful abstractions** like chains, agents, and memory that enable developers to create sophisticated workflows such as conversational AI with context, retrieval-augmented generation (RAG), and autonomous agents that can use tools. Additionally, its **composable architecture (LCEL)** makes it easy to build, test, and maintain complex AI pipelines by breaking them into reusable components that can be combined in different ways."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32b1609",
   "metadata": {},
   "source": [
    "## Mistral AI Models Overview\n",
    "\n",
    "Mistral AI offers several powerful language models:\n",
    "\n",
    "### Text-Only Models\n",
    "\n",
    "| Model | Description | Use Case |\n",
    "|-------|-------------|----------|\n",
    "| `mistral-large-latest` | Most capable text model | Complex reasoning, coding |\n",
    "| `mistral-small-latest` | Efficient and cheaper text model | General tasks, cost-effective |\n",
    "| `open-mistral-7b` | Open-source base model | Fine-tuning, experimentation |\n",
    "| `open-mixtral-8x7b` | Mixture of experts | High performance tasks |\n",
    "| `open-mixtral-8x22b` | Larger MoE model | Advanced reasoning |\n",
    "\n",
    "### Multimodal Models (Text + Images)\n",
    "\n",
    "| Model | Description | Use Case |\n",
    "|-------|-------------|----------|\n",
    "| `pixtral-12b-2409` | Multimodal model | Image + text tasks |\n",
    "| `pixtral-large-latest` | Larger multimodal | Complex vision tasks |\n",
    "\n",
    "**Note**: Mistral models do NOT support:\n",
    "- ‚ùå `logprobs` (token log probabilities)\n",
    "- ‚ùå Some OpenAI-specific features\n",
    "\n",
    "For this tutorial, we'll primarily use `mistral-small-latest` for text-based tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ccd432",
   "metadata": {},
   "source": [
    "## Basic Usage of ChatMistralAI\n",
    "\n",
    "Let's start by creating a basic ChatMistralAI object and making simple queries.\n",
    "\n",
    "### Parameters:\n",
    "\n",
    "- `temperature`: Controls randomness (0.0 = deterministic, 1.0 = sample from the output distribution, 2.0 = sample from a modified output distribution)\n",
    "- `model`: Specifies which Mistral model to use\n",
    "- `max_tokens`: Maximum number of tokens in the response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e4fdc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Answer]: content='The capital of France is **Paris**.\\n\\nParis is known for its iconic landmarks such as the **Eiffel Tower**, **Louvre Museum**, and **Notre-Dame Cathedral**, as well as its rich history, culture, and cuisine. It is one of the most visited cities in the world.\\n\\nWould you like to know more about Paris or France? üòä' additional_kwargs={} response_metadata={'token_usage': {'prompt_tokens': 10, 'total_tokens': 86, 'completion_tokens': 76}, 'model': 'mistral-small-latest', 'finish_reason': 'stop'} id='run--94da3af0-5781-474c-a4c6-4f6b129d011d-0' usage_metadata={'input_tokens': 10, 'output_tokens': 76, 'total_tokens': 86}\n"
     ]
    }
   ],
   "source": [
    "from langchain_mistralai import ChatMistralAI\n",
    "\n",
    "# Create the ChatMistralAI object\n",
    "llm = ChatMistralAI(\n",
    "    temperature=0.1,  # Low temperature for more focused responses\n",
    "    model=\"mistral-small-latest\", \n",
    ")\n",
    "\n",
    "question = \"What is the capital of France?\"\n",
    "\n",
    "print(f\"[Answer]: {llm.invoke(question)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e97aec",
   "metadata": {},
   "source": [
    "### Response Format (AI Message)\n",
    "\n",
    "When using the `ChatMistralAI` object, the response is returned as an AI Message with:\n",
    "\n",
    "### Response Format (AI Message)\n",
    "When using the ```ChatOpenAI``` object, the response is returned in the format of an AI Message. This includes the text content generated by the model along with any metadata or additional properties associated with the response. These provide structured information about the AI's reply and how it was generated.\n",
    "\n",
    "**Key Components of AI Message**\n",
    "1. **```content```**  \n",
    "   - **Definition:** The primary response text generated by the AI.  \n",
    "   - **Example:** **\"The capital of South Korea is Seoul.\"**\n",
    "   - **Purpose:** This is the main part of the response that users interact with.\n",
    "\n",
    "2. **```response_metadata```**  \n",
    "   - **Definition:** Metadata about the response generation process.  \n",
    "   - **Key Fields:**\n",
    "     - **```model_name``` :** Name of the model used (e.g., ```\"gpt-4o-mini\"``` ).\n",
    "     - **```finish_reason``` :** Reason the generation stopped (**stop** for normal completion).\n",
    "     - **```token_usage``` :** Token usage details:\n",
    "       - **```prompt_tokens``` :** Tokens used for the input query.\n",
    "       - **```completion_tokens``` :** Tokens used for the response.\n",
    "       - **```total_tokens``` :** Combined token count.\n",
    "\n",
    "3. **```id```**  \n",
    "   - **Definition:** A unique identifier for the API call.  \n",
    "   - **Purpose:** Useful for tracking or debugging specific interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "259e9ed3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"The capital of Japan is **Tokyo**. It is the largest city in Japan and serves as the country's political, economic, and cultural center. Tokyo is known for its bustling streets, modern technology, and rich history, including landmarks like the Imperial Palace, Shibuya Crossing, and historic temples.\", additional_kwargs={}, response_metadata={'token_usage': {'prompt_tokens': 10, 'total_tokens': 72, 'completion_tokens': 62}, 'model': 'mistral-small-latest', 'finish_reason': 'stop'}, id='run--142e288b-a0c3-4993-86d1-689f1998c932-0', usage_metadata={'input_tokens': 10, 'output_tokens': 62, 'total_tokens': 72})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Query content\n",
    "question = \"What is the capital of Japan?\"\n",
    "\n",
    "# Get full response\n",
    "response = llm.invoke(question)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3fb2948e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: The capital of Japan is **Tokyo**. It is the largest city in Japan and serves as the country's political, economic, and cultural center. Tokyo is known for its bustling streets, modern technology, and rich history, including landmarks like the Imperial Palace, Shibuya Crossing, and historic temples.\n",
      "Model: mistral-small-latest\n",
      "Token Usage: {'prompt_tokens': 10, 'total_tokens': 72, 'completion_tokens': 62}\n"
     ]
    }
   ],
   "source": [
    "# Extract key components\n",
    "content = response.content\n",
    "model_name = response.response_metadata.get(\"model\", \"Unknown\")\n",
    "token_usage = response.response_metadata.get(\"token_usage\", {})\n",
    "\n",
    "# Print results\n",
    "print(f\"Response: {content}\")\n",
    "print(f\"Model: {model_name}\")\n",
    "print(f\"Token Usage: {token_usage}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2cb42d5",
   "metadata": {},
   "source": [
    "### Streaming Output\n",
    "\n",
    "The streaming option allows you to receive real-time responses token by token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cbf6535c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certainly! Here are five stunning tourist destinations in Europe, each offering unique beauty and cultural richness:\n",
      "\n",
      "### 1. **Santorini, Greece**\n",
      "   - Famous for its whitewashed buildings, blue-domed churches, and breathtaking sunsets over the Aegean Sea. The volcanic island offers luxury resorts, wine tours, and stunning cliffside views in Oia.\n",
      "\n",
      "### 2. **Plitvice Lakes National Park, Croatia**\n",
      "   - A UNESCO World Heritage Site featuring cascading turquoise lakes, waterfalls, and lush forests. The wooden walkways and boat rides make it a paradise for nature lovers.\n",
      "\n",
      "### 3. **Hallstatt, Austria**\n",
      "   - A picturesque lakeside village nestled in the Alps, known for its charming pastel houses, crystal-clear lake, and salt mines. It‚Äôs often called one of the most beautiful places on Earth.\n",
      "\n",
      "### 4. **Cinque Terre, Italy**\n",
      "   - A colorful coastal region in Liguria with five vibrant villages (Monterosso, Vernazza, Corniglia, Manarola, and Riomaggiore). Hiking trails, vineyards, and cliffside views make it a dream destination.\n",
      "\n",
      "### 5. **Bruges, Belgium**\n",
      "   - A fairy-tale medieval city with cobblestone streets, canals, and Gothic architecture. The Belfry Tower, Market Square, and horse-drawn carriage rides add to its enchanting charm.\n",
      "\n",
      "Each of these destinations offers a unique blend of natural beauty, history, and culture, making them must-visit spots in Europe! Would you like recommendations for a specific type of travel experience?"
     ]
    }
   ],
   "source": [
    "answer = llm.stream(\n",
    "    \"Please provide 5 beautiful tourist destinations in Europe along with brief descriptions!\"\n",
    ")\n",
    "\n",
    "# Streaming real-time output\n",
    "for token in answer:\n",
    "    print(token.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b15a414",
   "metadata": {},
   "source": [
    "## Building Chains with LCEL\n",
    "\n",
    "LCEL (LangChain Expression Language) uses a simple pipe operator (`|`) to chain components together, creating powerful data processing pipelines. This powerful pattern offers several benefits: modularity allows each component (prompt, model, parser) to be developed and tested independently; reusability enables components to be mixed and matched across different chains; readability makes the data flow intuitive and easy to understand through the pipe operator; composability enables complex workflows to be built by combining simple chains; and maintainability ensures that changes to one component don't affect others in the chain.\n",
    "\n",
    "### Basic Chain: Prompt + Model + Output Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8a9ea9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['country'], input_types={}, partial_variables={}, template='What is the capital of {country}?')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Define template\n",
    "template = \"What is the capital of {country}?\"\n",
    "\n",
    "# Create a PromptTemplate\n",
    "prompt_template = PromptTemplate.from_template(template)\n",
    "prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "888217f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the capital of Germany?\n"
     ]
    }
   ],
   "source": [
    "# Test the prompt\n",
    "prompt = prompt_template.format(country=\"Germany\")\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f3fd9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"The capital of Spain is **Madrid**. It is the largest city in Spain and serves as the country's political, economic, and cultural center. Madrid is also home to the Spanish royal palace, the government headquarters, and numerous museums, including the famous **Prado Museum** and **Reina Sof√≠a Museum**.\\n\\nWould you like to know more about Madrid or Spain in general? üòä\", additional_kwargs={}, response_metadata={'token_usage': {'prompt_tokens': 10, 'total_tokens': 90, 'completion_tokens': 80}, 'model': 'mistral-small-latest', 'finish_reason': 'stop'}, id='run--c5c2bf2f-8a4f-4776-9566-5b583b93fd31-0', usage_metadata={'input_tokens': 10, 'output_tokens': 80, 'total_tokens': 90})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the Mistral model\n",
    "model = ChatMistralAI(model=\"mistral-small-latest\", temperature=0.1)\n",
    "\n",
    "# Create a simple chain that would take country as input and return the \n",
    "# capital city without applying the format function\n",
    "chain = prompt_template | model\n",
    "\n",
    "# Test the chain\n",
    "input_data = {\"country\": \"Spain\"}\n",
    "chain.invoke(input_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b714d49",
   "metadata": {},
   "source": [
    "### Adding an Output Parser\n",
    "\n",
    "An output parser converts the AI message to a string format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a9b214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result type: <class 'str'>\n",
      "Result: The capital of Italy is **Rome**.\n",
      "\n",
      "Rome is not only the capital city but also one of the most historically significant cities in the world, known for its ancient ruins, art, and cultural heritage. It was the center of the Roman Empire and remains a major global city today.\n"
     ]
    }
   ],
   "source": [
    "# Add output parser to the chain to get clean string output from the dict response\n",
    "output_parser = StrOutputParser()\n",
    "chain = prompt_template | model | output_parser\n",
    "\n",
    "# Now the output is a clean string\n",
    "result = chain.invoke({\"country\": \"Italy\"})\n",
    "print(f\"Result type: {type(result)}\")\n",
    "print(f\"Result: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7759a1d",
   "metadata": {},
   "source": [
    "### Complex Template Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3a3dd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"You are an expert {role} with 10 years of experience.\n",
    "Please provide advice on the following topic.\n",
    "\n",
    "Topic: {topic}\n",
    "\n",
    "Format your response as:\n",
    "- Main Advice:\n",
    "- Key Points:\n",
    "- Recommendations:\n",
    "\"\"\"\n",
    "\n",
    "# Create prompt and chain\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "model = ChatMistralAI(model=\"mistral-small-latest\", temperature=0.3)\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "chain = prompt | model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dfc1a18a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### **Designing Scalable Microservices**\n",
      "\n",
      "#### **Main Advice:**\n",
      "When designing scalable microservices, prioritize **loose coupling, high cohesion, and resilience** while ensuring the system can handle growth in traffic, data, and complexity. Focus on **autonomy, observability, and fault tolerance** to maintain performance and reliability as the system evolves.\n",
      "\n",
      "---\n",
      "\n",
      "#### **Key Points:**\n",
      "1. **Domain-Driven Design (DDD)**\n",
      "   - Align microservices with business domains (bounded contexts) to ensure clear ownership and minimal inter-service dependencies.\n",
      "   - Use **event-driven architecture** for asynchronous communication where appropriate.\n",
      "\n",
      "2. **Statelessness & Caching**\n",
      "   - Design services to be stateless where possible to enable horizontal scaling.\n",
      "   - Implement **distributed caching** (e.g., Redis, Memcached) to reduce database load.\n",
      "\n",
      "3. **Resilience & Fault Tolerance**\n",
      "   - Use **circuit breakers** (e.g., Hystrix, Resilience4j) to prevent cascading failures.\n",
      "   - Implement **retries with backoff** and **fallback mechanisms** for transient failures.\n",
      "\n",
      "4. **Scalable Data Management**\n",
      "   - Choose the right database per service (polyglot persistence).\n",
      "   - Use **event sourcing** or **CQRS** for high-write or high-read scenarios.\n",
      "   - Implement **database sharding** or **read replicas** for scalability.\n",
      "\n",
      "5. **API & Communication Design**\n",
      "   - Use **RESTful APIs** or **gRPC** for synchronous communication.\n",
      "   - Prefer **event-driven messaging** (Kafka, RabbitMQ) for decoupled interactions.\n",
      "   - Implement **API gateways** (Kong, Apigee) for routing, load balancing, and security.\n",
      "\n",
      "6. **Observability & Monitoring**\n",
      "   - Instrument services with **distributed tracing** (Jaeger, Zipkin).\n",
      "   - Use **metrics** (Prometheus, Grafana) and **logging** (ELK, Loki) for real-time insights.\n",
      "   - Set up **automated alerts** for performance degradation.\n",
      "\n",
      "7. **Infrastructure & Deployment**\n",
      "   - Use **containerization** (Docker) and **orchestration** (Kubernetes) for dynamic scaling.\n",
      "   - Implement **CI/CD pipelines** for rapid, reliable deployments.\n",
      "   - Consider **serverless** (AWS Lambda, Azure Functions) for event-driven workloads.\n",
      "\n",
      "8. **Security & Compliance**\n",
      "   - Enforce **service-to-service authentication** (JWT, OAuth2).\n",
      "   - Use **mutual TLS (mTLS)** for secure inter-service communication.\n",
      "   - Follow **least privilege** principles for access control.\n",
      "\n",
      "---\n",
      "\n",
      "#### **Recommendations:**\n",
      "- **Start small, iterate, and refactor**‚Äîavoid over-engineering upfront.\n",
      "- **Automate everything** (scaling, monitoring, deployments) to reduce manual overhead.\n",
      "- **Benchmark and load-test** early to identify bottlenecks.\n",
      "- **Document contracts** (APIs, events, schemas) to ensure consistency.\n",
      "- **Adopt DevOps practices** (infrastructure as code, GitOps) for agility.\n",
      "\n",
      "By following these principles, you can build a **scalable, maintainable, and resilient** microservices architecture that grows with your business needs.\n"
     ]
    }
   ],
   "source": [
    "# Execute the chain\n",
    "response = chain.invoke({\n",
    "    \"role\": \"software architect\",\n",
    "    \"topic\": \"designing scalable microservices\"\n",
    "})\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc720a4",
   "metadata": {},
   "source": [
    "## LCEL Interfaces\n",
    "\n",
    "The LCEL Runnable protocol provides several standard interfaces:\n",
    "These interfaces allow you to interact with LCEL chains in different ways depending on your use case:\n",
    "\n",
    "### Synchronous Methods:\n",
    "\n",
    "- **`invoke()`**: Use when you need a single, immediate response. Perfect for one-off queries or interactive applications where you process one request at a time.\n",
    "\n",
    "- **`stream()`**: Use when you want to display responses progressively to users. Ideal for chatbots or UIs where showing partial results improves user experience and perceived responsiveness.\n",
    "\n",
    "- **`batch()`**: Use when you have multiple inputs to process efficiently. Optimizes resource usage by grouping network requests together, useful for bulk data processing or generating multiple variations.\n",
    "\n",
    "### Asynchronous Methods:\n",
    "\n",
    "Use in async/await contexts when you need non-blocking execution\n",
    "\n",
    "- `ainvoke()`: Async single execution\n",
    "- `astream()`: Async streaming\n",
    "- `abatch()`: Async batch execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "96af30f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple chain for demonstration\n",
    "prompt = PromptTemplate.from_template(\"Explain {topic} in 2 sentences.\")\n",
    "model = ChatMistralAI(model=\"mistral-small-latest\")\n",
    "chain = prompt | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c352aa",
   "metadata": {},
   "source": [
    "### invoke(): Single Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3b27a0c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantum computing leverages the principles of quantum mechanics, such as superposition and entanglement, to process information in ways that classical computers cannot, enabling faster solutions to complex problems like cryptography, optimization, and simulation. Unlike classical bits, quantum bits (qubits) can exist in multiple states simultaneously, allowing for exponential computational power in certain tasks.\n"
     ]
    }
   ],
   "source": [
    "# Single invocation\n",
    "result = chain.invoke({\"topic\": \"quantum computing\"})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93aa55ba",
   "metadata": {},
   "source": [
    "### stream(): Real-time Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f2f3502e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blockchain is a decentralized digital ledger that records transactions across a network of computers, ensuring transparency, security, and immutability through cryptographic hashing and consensus mechanisms. It eliminates the need for intermediaries by allowing peer-to-peer verification and trustless transactions."
     ]
    }
   ],
   "source": [
    "# Streaming output\n",
    "for token in chain.stream({\"topic\": \"blockchain technology\"}):\n",
    "    print(token, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebe8043",
   "metadata": {},
   "source": [
    "### batch(): Process Multiple Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c4726b3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Artificial intelligence (AI) refers to the simulation of human intelligence in machines that are programmed to learn, reason, and perform tasks autonomously. It encompasses technologies like machine learning, natural language processing, and robotics to solve complex problems and improve decision-making.\n",
      "\n",
      "2. Machine learning is a subset of artificial intelligence that enables systems to learn and improve from experience without being explicitly programmed, using algorithms to identify patterns in data. It involves training models on data to make predictions or decisions, improving accuracy over time as they process more information.\n",
      "\n",
      "3. Deep learning is a subset of machine learning that uses artificial neural networks with multiple layers to automatically learn and extract hierarchical features from data. It excels at tasks like image recognition, natural language processing, and decision-making by processing vast amounts of data through deep, interconnected layers.\n"
     ]
    }
   ],
   "source": [
    "# Batch processing\n",
    "topics = [\n",
    "    {\"topic\": \"artificial intelligence\"},\n",
    "    {\"topic\": \"machine learning\"},\n",
    "    {\"topic\": \"deep learning\"}\n",
    "]\n",
    "\n",
    "results = chain.batch(topics)\n",
    "for i, result in enumerate(results):\n",
    "    print(f\"\\n{i+1}. {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01094af0",
   "metadata": {},
   "source": [
    "### Controlling Concurrency in Batch\n",
    "\n",
    "Use `max_concurrency` to control how many requests run simultaneously. This can be usefull to respect rate limits set by the LLM APIs providers and to smoot the workload."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9a265593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Neural networks are computational models inspired by the human brain, consisting of interconnected layers of artificial neurons that process and transmit information to learn patterns from data. They can recognize complex relationships, make predictions, and improve their accuracy through training on large datasets.\n",
      "\n",
      "2. Natural language processing (NLP) is a branch of artificial intelligence that enables computers to understand, interpret, and generate human language by analyzing text and speech data. It powers applications like chatbots, translation tools, and sentiment analysis by using algorithms to process and derive meaning from language patterns.\n",
      "\n",
      "3. Computer vision is a field of artificial intelligence that enables machines to interpret and understand visual data from the world, such as images or videos, by using algorithms and deep learning models. It allows applications like object detection, facial recognition, and autonomous navigation by analyzing patterns and extracting meaningful information from visual inputs.\n",
      "\n",
      "4. Reinforcement learning (RL) is a type of machine learning where an agent learns to make decisions by interacting with an environment, receiving rewards or penalties to maximize cumulative reward over time. It involves trial-and-error exploration and exploitation of strategies to optimize performance in tasks like robotics, gaming, and autonomous systems.\n",
      "\n",
      "5. Generative AI creates new content‚Äîlike text, images, or music‚Äîby learning patterns from existing data, often using models like neural networks. It can produce realistic or creative outputs, from writing articles to designing artwork, based on user prompts or learned examples.\n"
     ]
    }
   ],
   "source": [
    "# Batch with concurrency control\n",
    "topics = [\n",
    "    {\"topic\": \"neural networks\"},\n",
    "    {\"topic\": \"natural language processing\"},\n",
    "    {\"topic\": \"computer vision\"},\n",
    "    {\"topic\": \"reinforcement learning\"},\n",
    "    {\"topic\": \"generative AI\"}\n",
    "]\n",
    "\n",
    "results = chain.batch(topics, config={\"max_concurrency\": 2})\n",
    "for i, result in enumerate(results):\n",
    "    print(f\"\\n{i+1}. {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5038741d",
   "metadata": {},
   "source": [
    "### Async Methods\n",
    "\n",
    "Async methods are useful for concurrent operations in async environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1630d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[Starting stream for: edge computing]\n",
      "\n",
      "\n",
      "[Starting stream for: quantum computing]\n",
      "\n",
      "\n",
      "[Starting stream for: blockchain]\n",
      "[edge] [quan] [bloc] [edge] Edge[quan] Quant[bloc] Block[edge]  computing[quan] um[bloc] chain[quan]  computing[edge]  processes[bloc]  is[edge]  data[quan]  lever[quan] ages[quan]  the[bloc]  a[edge]  closer[quan]  principles[bloc]  decentral[quan]  of[bloc] ized[edge]  to[bloc]  digital[quan]  quantum[quan]  mechanics[bloc]  led[edge]  where[edge]  it[edge] ‚Äôs[quan] ,[quan]  such[edge]  generated[bloc] ger[edge]  ([edge] like[quan]  as[bloc]  that[quan]  super[bloc]  records[quan] position[edge]  Io[edge] T[edge]  devices[bloc]  transactions[quan]  and[edge]  or[quan]  ent[bloc]  across[quan] ang[edge]  sensors[bloc]  a[quan] lement[quan] ,[bloc]  network[edge] )[quan]  to[bloc]  of[edge]  to[edge]  reduce[quan]  perform[bloc]  computers[edge]  latency[quan]  calculations[bloc]  in[edge]  and[quan]  exponentially[edge]  bandwidth[bloc]  a[quan]  faster[edge]  usage[bloc]  secure[edge] ,[quan]  than[bloc] ,[edge]  improving[quan]  classical[quan]  computers[edge]  efficiency[bloc]  transparent[quan]  for[edge]  and[quan]  certain[bloc] ,[edge]  real[quan]  problems[edge] -time[quan] .[edge]  decision[quan]  By[edge] -making[quan]  using[edge] .[quan]  quantum[edge]  It[edge]  contrasts[quan]  bits[edge]  with[quan]  ([quan] qu[edge]  cloud[quan] bits[edge]  computing[quan] ),[edge]  by[edge]  decentral[quan]  which[edge] izing[quan]  can[quan]  exist[bloc]  and[edge]  data[quan]  in[edge]  processing[bloc]  tam[edge]  to[quan]  multiple[edge]  the[quan]  states[bloc] per[bloc] -pro[edge]  \"[quan]  simultaneously[bloc] of[quan] ,[edge] edge[quan]  it[edge] \"[bloc]  way[quan]  enables[edge]  of[quan]  breakthrough[edge]  the[bloc] .[bloc]  It[edge]  network[bloc]  ensures[quan] s[edge] ,[quan]  in[edge]  near[quan]  crypt[bloc]  trust[edge]  the[bloc]  and[quan] ography[edge]  source[quan] ,[bloc]  eliminates[edge] .[quan]  optimization[bloc]  intermedi[edge] [quan] ,[bloc] aries[quan]  and[bloc]  by[quan]  complex[bloc]  using\n",
      "[Completed: edge computing]\n",
      "[bloc]  crypt[quan]  simulations[quan] .[bloc] ographic[bloc]  techniques[bloc]  and[quan] \n",
      "[Completed: quantum computing]\n",
      "[bloc]  consensus[bloc]  mechanisms[bloc]  to[bloc]  validate[bloc]  and[bloc]  link[bloc]  data[bloc]  blocks[bloc]  in[bloc]  a[bloc]  chain[bloc] .[bloc] \n",
      "[Completed: blockchain]\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "\n",
    "# Async stream - demonstrate asynchronicity with multiple concurrent streams running at the same time\n",
    "async def demonstrate_async_streaming():\n",
    "    topics = [\"edge computing\", \"quantum computing\", \"blockchain\"]\n",
    "    \n",
    "    async def stream_topic(topic_name):\n",
    "        print(f\"\\n\\n[Starting stream for: {topic_name}]\")\n",
    "        async for token in chain.astream({\"topic\": topic_name}):\n",
    "            print(f\"[{topic_name[:4]}] {token}\", end=\"\", flush=True)\n",
    "        print(f\"\\n[Completed: {topic_name}]\")\n",
    "    \n",
    "    # Run all streams concurrently to show async behavior\n",
    "    await asyncio.gather(*[stream_topic(topic) for topic in topics])\n",
    "\n",
    "# Execute the async function\n",
    "await demonstrate_async_streaming()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "642070cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloud computing delivers computing services‚Äîlike servers, storage, databases, and software‚Äîover the internet, allowing users to access and scale resources on demand without managing physical infrastructure. It offers flexibility, cost-efficiency, and global accessibility by leveraging remote data centers.\n"
     ]
    }
   ],
   "source": [
    "# Async invoke\n",
    "result = await chain.ainvoke({\"topic\": \"cloud computing\"})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9db72ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. The Internet of Things (IoT) refers to a network of physical devices embedded with sensors, software, and connectivity to collect and exchange data over the internet. It enables smart automation, real-time monitoring, and data-driven decision-making across industries like healthcare, manufacturing, and smart homes.\n",
      "\n",
      "2. 5G is the fifth generation of wireless technology, offering significantly faster speeds, lower latency, and greater capacity than previous generations, enabling advanced applications like IoT, autonomous vehicles, and virtual reality. It operates on higher frequency bands and uses advanced technologies like beamforming and network slicing to deliver more efficient and reliable connectivity.\n",
      "\n",
      "3. Cybersecurity is the practice of protecting internet-connected systems, including hardware, software, and data, from digital attacks, damage, or unauthorized access. It involves implementing technologies, processes, and policies to safeguard sensitive information and maintain the integrity, confidentiality, and availability of digital assets.\n"
     ]
    }
   ],
   "source": [
    "# Async batch\n",
    "topics = [\n",
    "    {\"topic\": \"IoT\"},\n",
    "    {\"topic\": \"5G technology\"},\n",
    "    {\"topic\": \"cybersecurity\"}\n",
    "]\n",
    "\n",
    "results = await chain.abatch(topics)\n",
    "for i, result in enumerate(results):\n",
    "    print(f\"\\n{i+1}. {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6106562d",
   "metadata": {},
   "source": [
    "## Parallel Execution\n",
    "\n",
    "LCEL supports parallel execution using `RunnableParallel`, allowing multiple chains to run simultaneously.\n",
    "\n",
    "This is useful when you need to:\n",
    "- Get different types of information about the same topic\n",
    "- Process the same input through different chains\n",
    "- Combine results from multiple models or prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1a36eeaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableParallel\n",
    "\n",
    "# Create multiple chains\n",
    "capital_chain = (\n",
    "    PromptTemplate.from_template(\"What is the capital of {country}?\")\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "population_chain = (\n",
    "    PromptTemplate.from_template(\"What is the population of {country}?\")\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "language_chain = (\n",
    "    PromptTemplate.from_template(\"What languages are spoken in {country}?\")\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Combine chains in parallel\n",
    "parallel_chain = RunnableParallel(\n",
    "    capital=capital_chain,\n",
    "    population=population_chain,\n",
    "    language=language_chain\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7e197c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capital: The capital of Japan is **Tokyo**. It is the largest city in Japan and serves as the country's political, economic, and cultural center. Tokyo is also home to the Imperial Palace, the primary residence of the Emperor of Japan.\n",
      "\n",
      "Would you like to know more about Tokyo or other aspects of Japan?\n",
      "\n",
      "Population: As of the latest estimates (2024), the population of Japan is approximately **123.7 million** people.\n",
      "\n",
      "Japan has been experiencing a long-term decline in population due to low birth rates and an aging society. The population has been decreasing since around 2010, and projections suggest it will continue to shrink in the coming decades.\n",
      "\n",
      "For the most precise and up-to-date figures, you can refer to official sources like the **Statistics Bureau of Japan** or the **United Nations World Population Prospects**.\n",
      "\n",
      "Would you like additional demographic details (e.g., age distribution, urban vs. rural populations)?\n",
      "\n",
      "Language: In Japan, the primary language spoken is **Japanese (Êó•Êú¨Ë™û, *Nihongo*)**, which is the official and most widely used language. However, there are also several other languages and dialects spoken in the country:\n",
      "\n",
      "### **1. Japanese (Êó•Êú¨Ë™û, *Nihongo*)**\n",
      "   - The standard form is **Hy≈çjungo (Ê®ôÊ∫ñË™û)**, based on the dialect of Tokyo.\n",
      "   - There are numerous regional dialects, such as:\n",
      "     - **Kansai-ben** (Osaka, Kyoto, Kobe)\n",
      "     - **Kant≈ç-ben** (Tokyo and surrounding areas)\n",
      "     - **Hokkaid≈ç-ben** (Hokkaido)\n",
      "     - **Ky≈´sh≈´-ben** (Kyushu)\n",
      "     - **T≈çhoku-ben** (Northeastern Japan)\n",
      "     - **Hokkaid≈ç Ainu** (indigenous language, nearly extinct)\n",
      "\n",
      "### **2. Ryukyuan Languages (ÁêâÁêÉË™û, *Ry≈´ky≈´-go*)**\n",
      "   - Spoken in **Okinawa and the Amami Islands**, these are distinct from standard Japanese.\n",
      "   - Examples:\n",
      "     - **Okinawan (UchinƒÅguchi)**\n",
      "     - **Miyako**\n",
      "     - **Yaeyama**\n",
      "   - These languages are endangered due to the dominance of Japanese.\n",
      "\n",
      "### **3. Ainu Language („Ç¢„Ç§„ÉåË™û, *Ainu-go*)**\n",
      "   - Spoken by the **Ainu people**, an indigenous group in Hokkaido.\n",
      "   - Nearly extinct, with only a few elderly speakers remaining.\n",
      "\n",
      "### **4. Foreign Languages**\n",
      "   - Due to globalization, many people in urban areas speak:\n",
      "     - **English** (widely taught in schools but not widely fluent)\n",
      "     - **Chinese, Korean, Portuguese, Spanish, and others** (due to immigration and tourism)\n",
      "\n",
      "### **5. Sign Language (ÊâãË©±, *Shuwa*)**\n",
      "   - **Japanese Sign Language (JSL)** is used by the deaf community.\n",
      "\n",
      "Would you like more details on any of these?\n"
     ]
    }
   ],
   "source": [
    "# Execute individual chains\n",
    "print(\"Capital:\", capital_chain.invoke({\"country\": \"Japan\"}))\n",
    "print(\"\\nPopulation:\", population_chain.invoke({\"country\": \"Japan\"}))\n",
    "print(\"\\nLanguage:\", language_chain.invoke({\"country\": \"Japan\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4fc8f4a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parallel execution results:\n",
      "Capital: The capital of Japan is **Tokyo**. It is the largest city in Japan and serves as the country's political, economic, and cultural center.\n",
      "\n",
      "Tokyo became the official capital in 1869 when the Meiji government moved the imperial court from Kyoto to Edo (renamed Tokyo). Today, it is a bustling metropolis known for its modern skyscrapers, historic temples, and vibrant districts like Shibuya and Shinjuku.\n",
      "Population: As of 2024, the estimated population of **Japan** is approximately **124.3 million** people, according to the latest data from the **Statistics Bureau of Japan** and the **United Nations**.\n",
      "\n",
      "Japan has been experiencing a **declining population** due to low birth rates and an aging society. The population has been decreasing since 2010, and projections suggest it could fall below **100 million by 2050** if current trends continue.\n",
      "\n",
      "Would you like more details on demographics, such as age distribution or regional population changes?\n",
      "Language: In Japan, the primary language spoken is **Japanese (Êó•Êú¨Ë™û, *Nihongo*)**, which is the official and most widely used language. However, there are also several other languages and dialects spoken across the country, including:\n",
      "\n",
      "### **1. Japanese (Êó•Êú¨Ë™û, *Nihongo*)**\n",
      "   - The official and dominant language.\n",
      "   - Has multiple dialects, including:\n",
      "     - **Standard Japanese (Hy≈çjungo, Ê®ôÊ∫ñË™û)** ‚Äì Based on the Tokyo dialect.\n",
      "     - **Kansai-ben (Èñ¢Ë•øÂºÅ)** ‚Äì Spoken in the Kansai region (Osaka, Kyoto, Kobe).\n",
      "     - **Kanto-ben (Èñ¢Êù±ÂºÅ)** ‚Äì Spoken in the Kanto region (Tokyo, Yokohama).\n",
      "     - **Hokkaido-ben (ÂåóÊµ∑ÈÅìÂºÅ)** ‚Äì Spoken in Hokkaido.\n",
      "     - **Tohoku-ben (Êù±ÂåóÂºÅ)** ‚Äì Spoken in the Tohoku region.\n",
      "     - **Kyushu-ben (‰πùÂ∑ûÂºÅ)** ‚Äì Spoken in Kyushu.\n",
      "\n",
      "### **2. Ryukyuan Languages (ÁêâÁêÉË™û, *Ry≈´ky≈´-go*)**\n",
      "   - Spoken in **Okinawa** and the **Amami Islands**.\n",
      "   - Considered critically endangered due to assimilation with Japanese.\n",
      "   - Includes:\n",
      "     - **Okinawan (Uchinaguchi, „ÅÜ„Å°„Å™„Éº„Åê„Å°)** ‚Äì The most well-known.\n",
      "     - **Miyako, Yaeyama, Kunigami, and others.**\n",
      "\n",
      "### **3. Ainu Language („Ç¢„Ç§„ÉåË™û, *Ainu-go*)**\n",
      "   - Spoken by the **Ainu people**, indigenous to **Hokkaido** and parts of northern Japan.\n",
      "   - Nearly extinct, with only a few elderly speakers remaining.\n",
      "   - Efforts are being made to revive it.\n",
      "\n",
      "### **4. Other Minority and Immigrant Languages**\n",
      "   - **Korean (ÊúùÈÆÆË™û, *Ch≈çsen-go*)** ‚Äì Spoken by the Zainichi Korean community.\n",
      "   - **Chinese (‰∏≠ÂõΩË™û, *Ch≈´goku-go*)** ‚Äì Spoken by Chinese immigrants.\n",
      "   - **Portuguese („Éù„É´„Éà„Ç¨„É´Ë™û, *Porutogaru-go*)** ‚Äì Used by the **Kakure Kirishitan** (hidden Christian communities in Nagasaki).\n",
      "   - **English (Ëã±Ë™û, *Eigo*)** ‚Äì Widely taught in schools but not widely spoken fluently outside business and tourism.\n",
      "\n",
      "### **5. Sign Language (Êó•Êú¨ÊâãË©±, *Nihon Sh≈´wa*)**\n",
      "   - Used by the Deaf community in Japan.\n",
      "\n",
      "While Japanese is the dominant language, regional dialects and minority languages add to Japan's linguistic diversity. Would you like more details on any specific language?\n"
     ]
    }
   ],
   "source": [
    "# Execute all chains in parallel\n",
    "result = parallel_chain.invoke({\"country\": \"Japan\"})\n",
    "print(\"Parallel execution results:\")\n",
    "print(f\"Capital: {result['capital']}\")\n",
    "print(f\"Population: {result['population']}\")\n",
    "print(f\"Language: {result['language']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13dd7b5a",
   "metadata": {},
   "source": [
    "### Batch Processing with Parallel Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "74fc5388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Country 1 ===\n",
      "Capital: The capital of Brazil is **Bras√≠lia**. It was officially inaugurated as the capital on April 21, 1960, replacing Rio de Janeiro. Bras√≠lia is known for its modernist architecture and urban planning, designed by urban planner L√∫cio Costa and architect Oscar Niemeyer. It is a UNESCO World Heritage Site.\n",
      "Population: As of 2024, the estimated population of Brazil is approximately **216 million people**, making it the **6th most populous country in the world**.\n",
      "\n",
      "For the most up-to-date figures, you can check sources like:\n",
      "- **IBGE (Brazilian Institute of Geography and Statistics)** ‚Äì [www.ibge.gov.br](https://www.ibge.gov.br)\n",
      "- **World Bank** ‚Äì [data.worldbank.org](https://data.worldbank.org)\n",
      "- **United Nations Population Division** ‚Äì [population.un.org](https://population.un.org)\n",
      "\n",
      "Would you like historical population trends or demographic breakdowns?\n",
      "Language: Brazil is a linguistically diverse country, but the official language is **Portuguese**, spoken by nearly the entire population. However, there are several other languages and dialects spoken in different regions:\n",
      "\n",
      "### **1. Indigenous Languages**\n",
      "Brazil has over **200 indigenous languages**, including:\n",
      "- **Tupi-Guarani** (e.g., Tupi, Guarani)\n",
      "- **Macro-J√™** (e.g., Kaingang, Xavante)\n",
      "- **Arawak** (e.g., Terena)\n",
      "- **Karib** (e.g., Yanomami)\n",
      "- **Tukanoan** (e.g., Tikuna)\n",
      "\n",
      "### **2. Immigrant Languages**\n",
      "Due to historical immigration, some communities speak:\n",
      "- **German** (Southern Brazil, e.g., Pomeranian dialect)\n",
      "- **Italian** (Southern Brazil, e.g., Talian dialect)\n",
      "- **Japanese** (S√£o Paulo, especially in Liberdade district)\n",
      "- **Arabic** (Lebanese, Syrian, and Palestinian communities)\n",
      "- **Polish, Ukrainian, and other Slavic languages** (Southern Brazil)\n",
      "\n",
      "### **3. Sign Language**\n",
      "- **Libras (L√≠ngua Brasileira de Sinais)** is the official sign language for the deaf community.\n",
      "\n",
      "### **4. Other Influences**\n",
      "- **Afro-Brazilian languages** (e.g., Quimbundo, Kimbundu, Umbundu) are spoken by some Afro-descendant communities.\n",
      "- **Creole languages** (e.g., Papiamento in some Caribbean-influenced areas).\n",
      "\n",
      "While Portuguese dominates, Brazil's linguistic diversity reflects its rich cultural heritage. Would you like details on a specific language or region?\n",
      "\n",
      "=== Country 2 ===\n",
      "Capital: The capital of Australia is **Canberra**.\n",
      "\n",
      "While Sydney and Melbourne are larger and more well-known cities, Canberra was specifically chosen as a compromise capital when Australia federated in 1901. It is located in the Australian Capital Territory (ACT) and is home to important national institutions, including Parliament House, the High Court, and many national museums and galleries.\n",
      "Population: As of 2024, the estimated population of **Australia** is approximately **26.5 million people**.\n",
      "\n",
      "For the most up-to-date and precise figures, you can refer to official sources such as:\n",
      "- **Australian Bureau of Statistics (ABS)** ([www.abs.gov.au](https://www.abs.gov.au))\n",
      "- **World Bank** ([data.worldbank.org](https://data.worldbank.org))\n",
      "- **United Nations Population Division** ([population.un.org](https://population.un.org))\n",
      "\n",
      "Would you like historical trends or projections for future population growth?\n",
      "Language: Australia is a multicultural country with a diverse range of languages spoken. Here are the main languages:\n",
      "\n",
      "### **1. English (Official Language)**\n",
      "   - The primary language spoken by the majority of Australians.\n",
      "   - Used in government, education, media, and daily life.\n",
      "\n",
      "### **2. Indigenous Languages**\n",
      "   - **Aboriginal and Torres Strait Islander languages** (over 250 historically, but many are endangered or extinct).\n",
      "   - Some still spoken include **Warlpiri, Arrernte, Pitjantjatjara, Yol≈ãu Matha, and Kriol** (a creole language).\n",
      "\n",
      "### **3. Immigrant and Community Languages**\n",
      "   - Due to immigration, many languages are spoken in Australian communities, including:\n",
      "     - **Mandarin, Cantonese, Arabic, Vietnamese, Italian, Greek, Punjabi, Hindi, Spanish, Filipino (Tagalog), Korean, Japanese, and Turkish**.\n",
      "\n",
      "### **4. Sign Language**\n",
      "   - **Auslan (Australian Sign Language)** is used by the Deaf community.\n",
      "\n",
      "### **5. Other Languages**\n",
      "   - Some Australians also speak **French, German, Dutch, and other European languages**.\n",
      "\n",
      "Would you like details on a specific language or region in Australia?\n"
     ]
    }
   ],
   "source": [
    "# Batch process multiple countries\n",
    "countries = [\n",
    "    {\"country\": \"Brazil\"},\n",
    "    {\"country\": \"Australia\"}\n",
    "]\n",
    "\n",
    "results = parallel_chain.batch(countries)\n",
    "\n",
    "for i, result in enumerate(results):\n",
    "    print(f\"\\n=== Country {i+1} ===\")\n",
    "    print(f\"Capital: {result['capital']}\")\n",
    "    print(f\"Population: {result['population']}\")\n",
    "    print(f\"Language: {result['language']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe2be9a",
   "metadata": {},
   "source": [
    "## Using Mistral AI Without LangChain\n",
    "\n",
    "While LangChain provides a convenient abstraction layer, you can also use Mistral AI directly through their official Python client library. This approach gives you more direct control and can be simpler for basic use cases.\n",
    "\n",
    "### Installation\n",
    "\n",
    "Install the official Mistral AI client library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b68482b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\FKY\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\~aml'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain-chroma 0.1.2 requires langchain-core<0.3,>=0.1.40, but you have langchain-core 0.3.63 which is incompatible.\n",
      "langchain-nomic 0.1.2 requires langchain-core<0.3,>=0.1.46, but you have langchain-core 0.3.63 which is incompatible.\n",
      "langchain-nomic 0.1.2 requires pillow<11.0.0,>=10.3.0, but you have pillow 11.3.0 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.3\n",
      "[notice] To update, run: C:\\Users\\FKY\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install -q mistralai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07465b80",
   "metadata": {},
   "source": [
    "### Basic Example: Simple Chat Completion\n",
    "\n",
    "Here's a simple example of using Mistral AI directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b845462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: The capital of France is **Paris**.\n",
      "\n",
      "Paris is known for its iconic landmarks such as the **Eiffel Tower**, **Louvre Museum**, and **Notre-Dame Cathedral**, as well as its rich history, culture, and influence in art, fashion, and cuisine. It is one of the most visited cities in the world.\n",
      "\n",
      "Would you like to know more about Paris or France? üòä\n",
      "\n",
      "Model used: mistral-small-latest\n",
      "Tokens used: prompt_tokens=10 completion_tokens=83 total_tokens=93 prompt_audio_seconds=Unset()\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from mistralai import Mistral\n",
    "\n",
    "# Initialize the Mistral client with your API key\n",
    "client = Mistral(api_key=os.getenv(\"MISTRAL_API_KEY\"))\n",
    "\n",
    "# Create a simple chat completion\n",
    "response = client.chat.complete(\n",
    "    model=\"mistral-small-latest\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"What is the capital of France?\"\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Print the response\n",
    "print(\"Response:\", response.choices[0].message.content)\n",
    "print(\"\\nModel used:\", response.model)\n",
    "print(\"Tokens used:\", response.usage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af416616",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this comprehensive tutorial, you learned:\n",
    "\n",
    "1. **Mistral AI Models**: Different model types and their capabilities\n",
    "2. **Basic Usage**: How to create and use ChatMistralAI objects\n",
    "3. **LCEL Chains**: Building chains with prompts, models, and parsers\n",
    "4. **LCEL Interfaces**: Using invoke, stream, batch, and async methods\n",
    "5. **Parallel Execution**: Running multiple chains simultaneously\n",
    "\n",
    "### Key Takeaways:\n",
    "\n",
    "- Mistral models are powerful alternatives to OpenAI for text-based tasks\n",
    "- LCEL provides a clean, composable way to build AI applications\n",
    "- Parallel execution can significantly improve efficiency\n",
    "- Streaming enables real-time user feedback\n",
    "- Batch processing is useful for handling multiple inputs\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "- Explore more complex prompt templates\n",
    "- Implement error handling and retries\n",
    "- Combine Mistral with other LangChain components (memory, tools, agents)\n",
    "- Try multimodal models like Pixtral for vision tasks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
