{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99749405",
   "metadata": {},
   "source": [
    "# Using Mistral AI API (Pixtral Multimodal)\n",
    "\n",
    "- Author: Martin Fockedey with the help of Copilot\n",
    "- Based on: [LangChain Open Tutorial](https://github.com/LangChain-OpenTutorial/LangChain-OpenTutorial)\n",
    "\n",
    "## Overview\n",
    "\n",
    "This tutorial explains how to effectively use Mistral AI's **Pixtral** multimodal model with **LangChain**. You'll learn to set up and work with the `ChatMistralAI` object for tasks such as generating responses, analyzing model outputs, and leveraging features like real-time response streaming. By the end of this guide, you'll have the tools to experiment with and deploy Mistral AI multimodal solutions.\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "- [Overview](#overview)\n",
    "- [Environment Setup](#environment-setup)\n",
    "- [Mistral AI Pixtral Models](#mistral-ai-pixtral-models)\n",
    "- [Configuring Multimodal AI with System and User Prompts](#configuring-multimodal-ai-with-system-and-user-prompts)\n",
    "\n",
    "### References\n",
    "\n",
    "- [Mistral AI Documentation](https://docs.mistral.ai/)\n",
    "- [Mistral AI Models](https://docs.mistral.ai/getting-started/models/)\n",
    "- [LangChain Mistral Integration](https://python.langchain.com/docs/integrations/chat/mistralai)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b47aa9",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "Set up the environment.\n",
    "\n",
    "**[Note]**\n",
    "- You have one on your Teams group channel.\n",
    "- Store your API key in a `.env` file as `MISTRAL_API_KEY`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b8ddf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.3\n",
      "[notice] To update, run: C:\\Users\\FKY\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install -q python-dotenv langchain_mistralai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0b5643f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configuration file to manage the API KEY as an environment variable\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load API KEY information\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d245e51e",
   "metadata": {},
   "source": [
    "## Mistral AI Pixtral Models\n",
    "\n",
    "\n",
    "\n",
    "Multimodal refers to technologies or approaches that integrate and process multiple types of information (modalities). This includes a variety of data types such as:\n",
    "\n",
    "- Text: Information in written form, such as documents, books, or web pages.\n",
    "- Image: Visual information, including photos, graphics, or illustrations.\n",
    "- Audio: Auditory information, such as speech, music, or sound effects.\n",
    "- Video: A combination of visual and auditory information, including video clips or real-time streaming.\n",
    "\n",
    "Mistral AI offers powerful multimodal models under the **Pixtral** family:\n",
    "\n",
    "| Model | Description | Capabilities |\n",
    "|-------|-------------|-------------|\n",
    "| `pixtral-12b-2409` | 12B multimodal model | Text + Image processing |\n",
    "| `pixtral-large-latest` | Larger multimodal model | Advanced vision + text tasks |\n",
    "\n",
    "### Key Features\n",
    "\n",
    "- ✅ **Text Generation**: High-quality text responses\n",
    "- ✅ **Image Understanding**: Analyze and describe images\n",
    "- ✅ **Streaming**: Real-time response generation\n",
    "- ✅ **Multiple Images**: Process multiple images in one request\n",
    "\n",
    "### Limitations\n",
    "\n",
    "**Note**: This tutorial uses `pixtral-12b-2409` for cost-effectiveness. For more complex tasks, consider `pixtral-large-latest`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98cba7b6",
   "metadata": {},
   "source": [
    "### Step 1: Setting up ChatMistralAI with Pixtral\n",
    "\n",
    "Create a `ChatMistralAI` object with the Pixtral model for multimodal tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5b4bd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_mistralai import ChatMistralAI\n",
    "# Create ChatMistralAI object with Pixtral model\n",
    "llm_vision = ChatMistralAI(\n",
    "    temperature=0.1,\n",
    "    model=\"pixtral-12b-2409\",  # Multimodal model\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47253e0",
   "metadata": {},
   "source": [
    "### Step 2: Encoding Images\n",
    "\n",
    "Images need to be encoded into **Base64** format. This function handles both URLs and local files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e633bf1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import base64\n",
    "import mimetypes\n",
    "from IPython.display import display, HTML, Image\n",
    "\n",
    "\n",
    "def encode_image(image_path_or_url):\n",
    "    \"\"\"Encode an image to base64 format from URL or local file.\"\"\"\n",
    "    if image_path_or_url.startswith(\"http://\") or image_path_or_url.startswith(\n",
    "        \"https://\"\n",
    "    ):\n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'\n",
    "        }\n",
    "        # Download image from URL\n",
    "        response = requests.get(image_path_or_url, headers=headers)\n",
    "        if response.status_code == 200:\n",
    "            image_content = response.content\n",
    "        else:\n",
    "            raise Exception(f\"Failed to download image: {response.status_code}\")\n",
    "        # Guess MIME type based on URL\n",
    "        mime_type, _ = mimetypes.guess_type(image_path_or_url)\n",
    "        if mime_type is None:\n",
    "            mime_type = \"application/octet-stream\"\n",
    "    else:\n",
    "        # Read image from local file\n",
    "        try:\n",
    "            with open(image_path_or_url, \"rb\") as image_file:\n",
    "                image_content = image_file.read()\n",
    "            # Guess MIME type based on file extension\n",
    "            mime_type, _ = mimetypes.guess_type(image_path_or_url)\n",
    "            if mime_type is None:\n",
    "                mime_type = \"application/octet-stream\"\n",
    "        except FileNotFoundError:\n",
    "            raise Exception(f\"File not found: {image_path_or_url}\")\n",
    "\n",
    "    # Base64 encode the image\n",
    "    return f\"data:{mime_type};base64,{base64.b64encode(image_content).decode()}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e91bb81",
   "metadata": {},
   "source": [
    "### Step 3: Test Image Encoding\n",
    "\n",
    "Let's test encoding and displaying an image from a URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b1fb69c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example: URL-based image\n",
    "IMAGE_URL = \"https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg\"\n",
    "encoded_image_url = encode_image(IMAGE_URL)\n",
    "display(Image(url=IMAGE_URL))  # Display the image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a5c8d8",
   "metadata": {},
   "source": [
    "### Step 4: Creating Multimodal Messages\n",
    "\n",
    "Create a message structure that includes both text and images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8da431d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vision_messages(encoded_image, user_prompt=\"Describe this image in detail.\"):\n",
    "    \"\"\"Create messages for vision tasks.\"\"\"\n",
    "    return [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": user_prompt},\n",
    "                {\"type\": \"image_url\", \"image_url\": {\"url\": encoded_image}},\n",
    "            ],\n",
    "        }\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390d4472",
   "metadata": {},
   "source": [
    "### Step 5: Get Vision Response\n",
    "\n",
    "Send the image to Pixtral and get a description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad94d924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Pixtral's Description ===\n",
      "The image captures a serene scene in nature. A wooden boardwalk, constructed from wooden planks, meanders through a field of tall, green grass. The boardwalk, appearing to be well-trodden, leads the viewer's eye towards the horizon. The sky above is a clear blue, dotted with fluffy white clouds. In the distance, a line of trees forms a natural boundary for the field. The perspective of the image is from the ground, looking down the boardwalk towards the horizon, giving a sense of depth and distance. The colors in the image are vibrant, with the green of the grass contrasting with the blue of the sky. The wooden planks of the boardwalk add a touch of rustic charm to the scene. The image does not contain any discernible text or human activity. The relative positions of the objects suggest a peaceful, untouched landscape.\n"
     ]
    }
   ],
   "source": [
    "# Create messages with the encoded image\n",
    "messages = create_vision_messages(\n",
    "    encoded_image_url,\n",
    "    \"Describe this image in detail. What do you see?\"\n",
    ")\n",
    "\n",
    "# Get response from Pixtral\n",
    "response = llm_vision.invoke(messages)\n",
    "print(\"\\n=== Pixtral's Description ===\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3262190a",
   "metadata": {},
   "source": [
    "### Step 6: Streaming Multimodal Response\n",
    "\n",
    "You can also stream the response for better user experience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b6f07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_vision_response(llm, messages):\n",
    "    \"\"\"Stream the vision model response.\"\"\"\n",
    "    print(\"\\n=== Streaming Response ===\")\n",
    "    for chunk in llm.stream(messages):\n",
    "        print(chunk.content, end=\"\", flush=True)\n",
    "    print()  # New line at the end\n",
    "\n",
    "\n",
    "# Stream the response\n",
    "stream_vision_response(llm_vision, messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68df9d78",
   "metadata": {},
   "source": [
    "## Configuring Multimodal AI with System and User Prompts\n",
    "\n",
    "Let's demonstrate how to use system and user prompts for specific tasks like analyzing charts or documents.\n",
    "\n",
    "### Understanding Prompts\n",
    "\n",
    "**System Prompt**\n",
    "- Defines the AI's role and behavior\n",
    "- Sets context for consistent responses\n",
    "- Example: \"You are an expert data analyst\"\n",
    "\n",
    "**User Prompt**\n",
    "- Provides specific task instructions\n",
    "- Guides what the user wants\n",
    "- Example: \"Analyze this chart and extract key metrics\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4316d3d1",
   "metadata": {},
   "source": [
    "### Example: Financial Chart Analysis\n",
    "\n",
    "Let's analyze a financial chart using Pixtral with custom prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b79cdba5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://media.wallstreetprep.com/uploads/2022/05/24100154/NVIDIA-Income-Statement.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example financial chart URL\n",
    "CHART_URL = \"https://media.wallstreetprep.com/uploads/2022/05/24100154/NVIDIA-Income-Statement.jpg\"\n",
    "\n",
    "# Encode and display the chart\n",
    "encoded_chart = encode_image(CHART_URL)\n",
    "display(Image(url=CHART_URL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c71270e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define system and user prompts for financial analysis\n",
    "system_prompt = \"\"\"You are a financial analyst expert specializing in reading and interpreting \n",
    "financial statements and charts. Your task is to analyze financial data and provide clear, \n",
    "actionable insights.\"\"\"\n",
    "\n",
    "user_prompt = \"\"\"Analyze this financial statement and provide:\n",
    "1. Key revenue trends\n",
    "2. Notable changes in metrics\n",
    "3. Overall financial health assessment\n",
    "4. Any concerning or positive patterns\n",
    "\n",
    "Be specific with numbers when possible.\"\"\"\n",
    "\n",
    "# Create messages with system prompt\n",
    "messages_with_system = [\n",
    "    {\"role\": \"system\", \"content\": system_prompt},\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"text\", \"text\": user_prompt},\n",
    "            {\"type\": \"image_url\", \"image_url\": {\"url\": encoded_chart}},\n",
    "        ],\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8788f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "FINANCIAL ANALYSIS\n",
      "============================================================\n",
      "\n",
      "### Key Revenue Trends\n",
      "1. **Revenue Growth**: NVIDIA's revenue has shown significant growth over the three years presented.\n",
      "   - January 30, 2022: $26,914 million\n",
      "   - January 31, 2021: $16,675 million\n",
      "   - January 26, 2020: $10,918 million\n",
      "   - This indicates a substantial increase in revenue, particularly from 2020 to 2021 and 2021 to 2022.\n",
      "\n",
      "### Notable Changes in Metrics\n",
      "1. **Cost of Revenue**: The cost of revenue has also increased but at a slower rate compared to revenue.\n",
      "   - January 30, 2022: $9,439 million\n",
      "   - January 31, 2021: $6,279 million\n",
      "   - January 26, 2020: $4,150 million\n",
      "   - This suggests that while revenue is growing, the cost of producing or acquiring the revenue is also rising.\n",
      "\n",
      "2. **Gross Profit**: Gross profit has seen a significant increase.\n",
      "   - January 30, 2022: $17,475 million\n",
      "   - January 31, 2021: $10,396 million\n",
      "   - January 26, 2020: $6,768 million\n",
      "   - This indicates improved profitability on a per-unit basis.\n",
      "\n",
      "3. **Operating Expenses**: Operating expenses have increased, particularly in Research and Development (R&D) and Sales, General, and Administrative (SG&A).\n",
      "   - Total Operating Expenses:\n",
      "     - January 30, 2022: $7,434 million\n",
      "     - January 31, 2021: $5,864 million\n",
      "     - January 26, 2020: $3,922 million\n",
      "   - R&D:\n",
      "     - January 30, 2022: $5,268 million\n",
      "     - January 31, 2021: $3,924 million\n",
      "     - January 26, 2020: $2,829 million\n",
      "   - SG&A:\n",
      "     - January 30, 2022: $2,166 million\n",
      "     - January 31, 2021: $1,940 million\n",
      "     - January 26, 2020: $1,093 million\n",
      "   - The increase in R&D expenses suggests a focus on innovation and future product development.\n",
      "\n",
      "4. **Income from Operations**: There is a notable increase in income from operations.\n",
      "   - January 30, 2022: $10,041 million\n",
      "   - January 31, 2021: $4,532 million\n",
      "   - January 26, 2020: $2,846 million\n",
      "   - This indicates improved operational efficiency and higher profitability from core operations.\n",
      "\n",
      "### Overall Financial Health Assessment\n",
      "1. **Net Income**: Net income has seen a substantial increase.\n",
      "   - January 30, 2022: $9,752 million\n",
      "   - January 31, 2021: $4,332 million\n",
      "   - January 26, 2020: $2,796 million\n",
      "   - This suggests that the company is becoming more profitable overall.\n",
      "\n",
      "2. **Net Income per Share**: Both basic and diluted net income per share have increased significantly.\n",
      "   - Basic:\n",
      "     - January 30, 2022: $3.91\n",
      "     - January 31, 2021: $1.76\n",
      "     - January 26, 2020: $1.15\n",
      "   - Diluted:\n",
      "     - January 30, 2022: $3.85\n",
      "     - January 31, 2021: $1.73\n",
      "     - January 26, 2020: $1.13\n",
      "   - This indicates improved profitability on a per-share basis, which is beneficial for shareholders.\n",
      "\n",
      "### Concerning or Positive Patterns\n",
      "1. **Positive Patterns**:\n",
      "   - Significant revenue growth.\n",
      "   - Increased gross profit and income from operations.\n",
      "   - Improved net income and net income per share.\n",
      "   - Substantial investment in R&D, which can lead to future innovations and growth.\n",
      "\n",
      "2. **Concerning Patterns**:\n",
      "   - Rising operating expenses, particularly in R&D and SG&A, which could impact profitability if not managed effectively.\n",
      "   - The cost of revenue is increasing, which may need to be monitored to ensure it does not erode margins.\n",
      "\n",
      "Overall, NVIDIA's financial health appears strong with significant growth in revenue and profitability. However, the company should keep an eye on rising operating expenses to ensure they do not outpace revenue growth.\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Get detailed financial analysis\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINANCIAL ANALYSIS\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "for chunk in llm_vision.stream(messages_with_system):\n",
    "    print(chunk.content, end=\"\", flush=True)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e738dede",
   "metadata": {},
   "source": [
    "### Example: Multiple Images Analysis\n",
    "\n",
    "Pixtral can analyze multiple images in a single request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2af1719d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 1:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg\" width=\"400\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image 2:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/1/15/Cat_August_2010-4.jpg/2560px-Cat_August_2010-4.jpg\" width=\"400\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example: Compare two images\n",
    "image1_url = \"https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg\"\n",
    "image2_url = \"https://upload.wikimedia.org/wikipedia/commons/thumb/1/15/Cat_August_2010-4.jpg/2560px-Cat_August_2010-4.jpg\"\n",
    "\n",
    "encoded_img1 = encode_image(image1_url)\n",
    "encoded_img2 = encode_image(image2_url)\n",
    "\n",
    "# Display both images\n",
    "print(\"Image 1:\")\n",
    "display(Image(url=image1_url, width=400))\n",
    "print(\"\\nImage 2:\")\n",
    "display(Image(url=image2_url, width=400))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5de240f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Comparison Analysis ===\n",
      "The two images presented are quite different in terms of content, setting, and mood. Here is a detailed comparison and contrast:\n",
      "\n",
      "### Image 1:\n",
      "- **Setting**: The image depicts a serene natural landscape with a wooden boardwalk extending into a grassy wetland or marsh area.\n",
      "- **Elements**: The boardwalk is surrounded by tall, green grasses and leads towards a distant horizon with trees and a partly cloudy sky.\n",
      "- **Mood**: The scene evokes a sense of tranquility, nature, and openness. The bright blue sky and the lush greenery contribute to a peaceful and refreshing atmosphere.\n",
      "\n",
      "### Image 2:\n",
      "- **Setting**: The image shows a domestic scene with a cat lying on a white ledge or window sill.\n",
      "- **Elements**: The cat is stretched out, with its paws extended and eyes closed, appearing relaxed and content. The background is a plain white wall.\n",
      "- **Mood**: The scene is cozy and intimate, focusing on the cat's relaxed posture, which conveys a sense of comfort and contentment.\n",
      "\n",
      "### Main Differences:\n",
      "1. **Environment**:\n",
      "   - Image 1: Natural outdoor setting with a boardwalk, grasses, and a sky.\n",
      "   - Image 2: Indoor or domestic setting with a cat on a ledge against a plain wall.\n",
      "\n",
      "2. **Subject Matter**:\n",
      "   - Image 1: Landscape and nature.\n",
      "   - Image 2: A domestic pet (cat).\n",
      "\n",
      "3. **Mood and Atmosphere**:\n",
      "   - Image 1: Tranquil, open, and refreshing.\n",
      "   - Image 2: Cozy, intimate, and comforting.\n",
      "\n",
      "4. **Color Palette**:\n",
      "   - Image 1: Dominated by greens and blues, with natural tones.\n",
      "   - Image 2: Predominantly white with the cat's natural fur colors.\n",
      "\n",
      "These differences highlight the contrast between the natural, expansive environment in the first image and the cozy, intimate setting in the second image."
     ]
    }
   ],
   "source": [
    "# Create message with multiple images\n",
    "multi_image_messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"text\", \"text\": \"Compare and contrast these two images. What are the main differences?\"},\n",
    "            {\"type\": \"image_url\", \"image_url\": {\"url\": encoded_img1}},\n",
    "            {\"type\": \"image_url\", \"image_url\": {\"url\": encoded_img2}},\n",
    "        ],\n",
    "    }\n",
    "]\n",
    "\n",
    "# Get comparison\n",
    "print(\"\\n=== Comparison Analysis ===\")\n",
    "for chunk in llm_vision.stream(multi_image_messages):\n",
    "    print(chunk.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75075644",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this tutorial, you learned:\n",
    "\n",
    "1. **Mistral AI Models**: Understanding Pixtral multimodal models\n",
    "3. **Image Processing**: Encoding and sending images to Pixtral\n",
    "4. **Multimodal Prompts**: Creating effective system and user prompts\n",
    "5. **Streaming**: Real-time response generation\n",
    "6. **Multiple Images**: Processing multiple images in one request\n",
    "\n",
    "\n",
    "### Best Practices\n",
    "\n",
    "1. **Use Specific Prompts**: Be clear about what you want to extract from images\n",
    "2. **Optimize Images**: Compress large images for faster processing\n",
    "3. **System Prompts**: Use system prompts to set expertise context\n",
    "4. **Streaming**: Enable streaming for better UX in interactive applications\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
